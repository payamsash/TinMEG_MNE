{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "import mne\n",
    "from mne.preprocessing import create_ecg_epochs, create_eog_epochs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import os\n",
    "import os.path as op\n",
    "from tqdm.notebook import tqdm\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from mne.coreg import Coregistration\n",
    "from mne.datasets import fetch_fsaverage\n",
    "from mne.minimum_norm import make_inverse_operator, apply_inverse\n",
    "from scipy import stats as stats\n",
    "from mne.stats import spatio_temporal_cluster_1samp_test, summarize_clusters_stc"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading MEG data (movement corrected) and defining events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading subject IDs (subject 697 cant be loaded and subject 859 has different dev_head_t during the two recordings)\n",
    "subjects_fname = '/Users/payamsadeghishabestari/KI_MEG/sub_date.txt'\n",
    "subject_ids = np.loadtxt(fname=subjects_fname, delimiter=',', skiprows=1, usecols=1)\n",
    "subject_ids = [int(s_id) for s_id in subject_ids]\n",
    "\n",
    "# find all the subject folders\n",
    "directory = '/Users/payamsadeghishabestari/KI_MEG/meg_rec_tinmeg2' \n",
    "folders_list = []\n",
    "for folder in sorted(os.listdir(directory)): ## iterate over folders in that directory\n",
    "    f = os.path.join(directory, folder)\n",
    "    if os.path.isdir(f): ## select only folders\n",
    "        folders_list.append(f)\n",
    "\n",
    "# create a dictionary of subjects with their files\n",
    "files_dict = {}\n",
    "for subject_id in subject_ids:\n",
    "    for folder in folders_list:\n",
    "        if f'{subject_id}' in folder:\n",
    "            f = os.path.join(folder, sorted(os.listdir(folder))[-1])\n",
    "            files_dict[f'{subject_id}'] = [f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating event dictionary\n",
    "# tinmeg1\n",
    "keys = ['PO60_70', 'PO60_75', 'PO60_80', 'PO60_85', 'PO60_90', 'PO60_95',\n",
    "        'PO70_75', 'PO70_80', 'PO70_85', 'PO70_90', 'PO70_95',\n",
    "        'GP60_i0', 'GP60_i60', 'GP60_i120', 'GP60_i240',\n",
    "        'GP70_i0', 'GP70_i60', 'GP70_i120', 'GP70_i240',\n",
    "        'GO_60', 'GO_70']\n",
    "values = [40968, 36872, 34824, 33800, 33288, 33032,\n",
    "        36876, 34828, 33804, 33292, 33036,\n",
    "        49800, 49736, 49704, 49688,\n",
    "        49804, 49740, 49708, 49692,\n",
    "        16386, 16390]\n",
    "events_dict_tinmeg1 = {}\n",
    "for key, value in zip(keys, values):\n",
    "        events_dict_tinmeg1[key] = value\n",
    "\n",
    "# tinmeg2\n",
    "keys = ['GPP_00', 'GPG_00', 'PO_00', 'GO_00', 'PPP_00', 'PPG_00',\n",
    "        'GPP_03', 'GPG_03', 'PO_03', 'GO_03',\n",
    "        'GPP_08', 'GPG_08', 'PO_08', 'GO_08',\n",
    "        'GPP_30', 'GPG_30', 'PO_30', 'GO_30',\n",
    "        'GPP_33', 'GPG_33', 'PO_33', 'GO_33',\n",
    "        'GPP_38', 'GPG_38', 'PO_38', 'GO_38',\n",
    "        'GPP_80', 'GPG_80', 'PO_80', 'GO_80',\n",
    "        'GPP_83', 'GPG_83', 'PO_83', 'GO_83',\n",
    "        'GPP_88', 'GPG_88', 'PO_88', 'GO_88']\n",
    "values = [1, 2, 4, 8, 16, 32,\n",
    "        49, 50, 52, 56,\n",
    "        33, 34, 36, 40,\n",
    "        193, 194, 196, 200,\n",
    "        241, 242, 244, 248,\n",
    "        225, 226, 228, 232,\n",
    "        129, 130, 132, 136,\n",
    "        177, 178, 180, 184,\n",
    "        161, 162, 164, 168]\n",
    "events_dict_tinmeg2 = {}\n",
    "for key, value in zip(keys, values):\n",
    "        events_dict_tinmeg2[key] = value\n",
    "\n",
    "#tinmeg3\n",
    "keys = ['GPP_00', 'GPG_00', 'PO_00', 'GO_00', 'PPP_00', 'PPG_00',\n",
    "        'GPP_03', 'GPG_03', 'PO_03', 'GO_03',\n",
    "        'GPP_08', 'GPG_08', 'PO_08', 'GO_08']\n",
    "values = [1, 2, 4, 8, 16, 32,\n",
    "        49, 50, 52, 56,\n",
    "        33, 34, 36, 40]\n",
    "events_dict_tinmeg3 = {}\n",
    "for key, value in zip(keys, values):\n",
    "        events_dict_tinmeg3[key] = value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maxwell Filtering and environmental noise reduction (if necessary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the empty room recordings before and after exp\n",
    "fname_empty_before = '/Users/payamsadeghishabestari/KI_MEG/697/empty_room_before.fif'\n",
    "fname_empty_after = '/Users/payamsadeghishabestari/KI_MEG/697/empty_room_after.fif'\n",
    "raw_empty_before = mne.io.read_raw_fif(fname=fname_empty_before, preload=True, allow_maxshield=True, verbose=False)\n",
    "raw_empty_after = mne.io.read_raw_fif(fname=fname_empty_after, preload=True, allow_maxshield=True, verbose=False)\n",
    "\n",
    "# compute projections for empty room recordings and concatenate them\n",
    "raw_empty_before.del_proj()\n",
    "raw_empty_after.del_proj()\n",
    "empty_room_before_projs = mne.compute_proj_raw(raw_empty_before, n_grad=2, n_mag=2, verbose=False)\n",
    "empty_room_after_projs = mne.compute_proj_raw(raw_empty_after, n_grad=2, n_mag=2, verbose=False)\n",
    "extended_proj = list(np.concatenate((np.array(empty_room_before_projs), np.array(empty_room_after_projs))))\n",
    "\n",
    "# load the experiment recording\n",
    "fname = '/Users/payamsadeghishabestari/KI_MEG/697/tinmeg1-1.fif'\n",
    "raw = mne.io.read_raw_fif(fname=fname, preload=True, allow_maxshield=True, verbose=False)\n",
    "\n",
    "# estimating continous head movement\n",
    "chpi_freqs, ch_idx, chpi_codes = mne.chpi.get_chpi_info(info=raw.info)\n",
    "chpi_amplitudes = mne.chpi.compute_chpi_amplitudes(raw)\n",
    "chpi_locs = mne.chpi.compute_chpi_locs(raw.info, chpi_amplitudes)\n",
    "head_pos = mne.chpi.compute_head_pos(raw.info, chpi_locs, verbose=True)\n",
    "\n",
    "# find bad channels\n",
    "noisy_chs, flat_chs = mne.preprocessing.find_bad_channels_maxwell(raw, head_pos=head_pos, verbose=True)\n",
    "bads = raw.info[\"bads\"] + noisy_chs + flat_chs\n",
    "raw.info[\"bads\"] = bads\n",
    "\n",
    "# apply movement corection and time-signal space seperation\n",
    "raw_sss = mne.preprocessing.maxwell_filter(raw, head_pos=head_pos, st_fixed=True,\n",
    "                                            extended_proj=extended_proj,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = '/Users/payamsadeghishabestari/KI_MEG/697/tinmeg1.fif'\n",
    "raw = mne.io.read_raw_fif(fname=fname, preload=True, allow_maxshield=True, verbose=False)\n",
    "\n",
    "# estimating continous head movement\n",
    "chpi_freqs, ch_idx, chpi_codes = mne.chpi.get_chpi_info(info=raw.info)\n",
    "chpi_amplitudes = mne.chpi.compute_chpi_amplitudes(raw)\n",
    "chpi_locs = mne.chpi.compute_chpi_locs(raw.info, chpi_amplitudes)\n",
    "head_pos = mne.chpi.compute_head_pos(raw.info, chpi_locs, verbose=True)\n",
    "\n",
    "# find bad channels\n",
    "noisy_chs, flat_chs = mne.preprocessing.find_bad_channels_maxwell(raw, head_pos=head_pos, verbose=True)\n",
    "bads = raw.info[\"bads\"] + noisy_chs + flat_chs\n",
    "raw.info[\"bads\"] = bads\n",
    "\n",
    "# apply movement corection and time-signal space seperation\n",
    "raw_sss = mne.preprocessing.maxwell_filter(raw, head_pos=head_pos, st_fixed=True, verbose=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfreq = 250\n",
    "(l_freq, h_freq) = (0.1, 40)\n",
    "(tmin, tmax) = (-0.3, 0.3) # baseline period of 300 ms\n",
    "reject_criteria = dict(grad=4000e-13, mag=4e-12, eog=250e-6)    # T/m  # T  # V\n",
    "flat_criteria = dict(mag=1e-15, grad=1e-13)  # 1 fT  # 1 fT/cm \n",
    "subjects = list(files_dict.keys())[:]\n",
    "\n",
    "# reading the MEG file\n",
    "for subject in tqdm(subjects): \n",
    "    start_time = time.time()\n",
    "    print(subject)\n",
    "    print('reading the MEG file, be patient ...')\n",
    "    fname = files_dict[subject][0]\n",
    "    raw = mne.io.read_raw_fif(fname=fname, preload=True, allow_maxshield=True, verbose=False)\n",
    "    #if raw.last_samp / raw.info['sfreq'] < 3000:\n",
    "    #    raise ValueError(f'All .fif files might not be loaded for subject {subject}')\n",
    "    events_orig = mne.find_events(raw, stim_channel=None, min_duration=0.005, shortest_event=1, uint_cast=True, verbose=False) # min_duration = 0\n",
    "\n",
    "    # delay compensation for tinmeg1 data\n",
    "    #delay = int((50 / 1000) * raw.info['sfreq']) # 50 ms delay \n",
    "    #po_ids = list(events_dict_tinmeg3.values())[:11] # only PO triggers\n",
    "    #for row in range(len(events_orig)):\n",
    "    #    if events_orig[row][2] in po_ids:\n",
    "    #        events_orig[row][0] = events_orig[row][0] - delay\n",
    "\n",
    "    # resampling and filtering the data\n",
    "    print('resampling and filtering the data, be patient, will last a while ...')\n",
    "    raw, events = raw.resample(sfreq=sfreq, events=events_orig, verbose=False)\n",
    "    raw = raw.filter(l_freq=l_freq, h_freq=h_freq, verbose=False) \n",
    "\n",
    "    # creating ECG and EOG evoked responses\n",
    "    ecg_evoked_meg,  ecg_evoked_grad = create_ecg_epochs(raw,\n",
    "                                    verbose=False).average().apply_baseline(baseline=(None, -0.2),\n",
    "                                    verbose=False).plot_joint(picks=['meg', 'grad'], show=False)\n",
    "    eog_evoked_meg,  eog_evoked_grad = create_eog_epochs(raw,\n",
    "                                    verbose=False).average().apply_baseline(baseline=(None, -0.2),\n",
    "                                    verbose=False).plot_joint(picks=['meg', 'grad'], show=False)\n",
    "\n",
    "    # computing ICA and remove ECG, saccade and muscle artifacts (if any) and interpolating (if any)\n",
    "    print('computing ICA (this might take a while) ...')\n",
    "    ica = mne.preprocessing.ICA(n_components=0.95, max_iter=800, method='infomax',\n",
    "                                random_state=42, fit_params=dict(extended=True)) \n",
    "    ica.fit(raw, verbose=False) \n",
    "    ecg_indices, ecg_scores = ica.find_bads_ecg(raw, method=\"ctps\", measure='zscore', verbose=False)\n",
    "    if len(ecg_indices) > 0:\n",
    "        ecg_component = ica.plot_properties(raw, picks=ecg_indices, verbose=False, show=False)\n",
    "    emg_indices, emg_scores = ica.find_bads_muscle(raw, verbose=False)\n",
    "    if len(emg_indices) > 0:\n",
    "        emg_component = ica.plot_properties(raw, picks=emg_indices, verbose=False, show=False)\n",
    "    eog_indices, eog_scores = ica.find_bads_eog(raw, ch_name='EOG002') \n",
    "    if len(eog_indices) > 0:\n",
    "        eog_component = ica.plot_properties(raw, picks=eog_indices, verbose=False, show=False)\n",
    "\n",
    "    exclude_idxs = ecg_indices + emg_indices\n",
    "    ica.apply(raw, exclude=exclude_idxs, verbose=False)\n",
    "    raw.interpolate_bads(verbose=False)\n",
    "\n",
    "    # event dict selection, epoching and dropping bad epochs \n",
    "    #if fname[-43] == '1':\n",
    "    #    events_dict = events_dict_tinmeg1\n",
    "    #if fname[-43] == '2':\n",
    "    #    events_dict = events_dict_tinmeg2\n",
    "    #if fname[-43] == '3':\n",
    "    #    events_dict = events_dict_tinmeg3\n",
    "    \n",
    "    events_dict = events_dict_tinmeg1\n",
    "    print('Epoching data ...')\n",
    "    epochs = mne.Epochs(raw, events, event_id=events_dict, tmin=tmin, tmax=tmax, baseline=(None, 0),\n",
    "                        reject=None, flat=None, preload=True, verbose=False) \n",
    "    dropped_epochs_fig = epochs.plot_drop_log(color=(0.6, 0.2, 0.4), width=0.4, show=False)\n",
    "\n",
    "    # creating a report\n",
    "    report = mne.Report(title=f'report_subject_{subject}', verbose=False)\n",
    "    report.add_raw(raw=raw, title='recording after preprocessing', butterfly=False, psd=False) \n",
    "    report.add_figure(fig=ecg_evoked_meg, title='ECG evoked MEG', image_format='PNG')\n",
    "    report.add_figure(fig=ecg_evoked_grad, title='ECG evoked Gradiometer', image_format='PNG')\n",
    "    report.add_figure(fig=eog_evoked_meg, title='EOG evoked MEG', image_format='PNG')\n",
    "    report.add_figure(fig=eog_evoked_grad, title='EOG evoked Gradiometer', image_format='PNG')\n",
    "    if len(ecg_indices) > 0:\n",
    "        report.add_figure(fig=ecg_component, title='ECG component', image_format='PNG')\n",
    "    if len(emg_indices) > 0:\n",
    "        report.add_figure(fig=emg_component, title='EMG component', image_format='PNG')\n",
    "    if len(eog_indices) > 0:\n",
    "        report.add_figure(fig=eog_component, title='EOG component (saccade)', image_format='PNG')    \n",
    "    report.add_figure(fig=dropped_epochs_fig, title='Dropped Epochs', image_format='PNG')\n",
    "    \n",
    "    # saving report and epochs\n",
    "    \n",
    "    fname_report = f'/Users/payamsadeghishabestari/KI_MEG/pending files/{subject}/report_subject_{subject}.html'\n",
    "    fname_epoch = f'/Users/payamsadeghishabestari/KI_MEG/pending files/{subject}/epochs_subject_{subject}-epo.fif'\n",
    "    report.save(fname=fname_report, open_browser=False, overwrite=True, verbose=False)\n",
    "    epochs.save(fname=fname_epoch, overwrite=True, verbose=False)\n",
    "    print(f'elapsed time for subject {subject} was {time.time() - start_time}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenating, creating evoked objects and grand averaging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create epochs dictionary (some needs concatenating)\n",
    "epochs_folder = '/Users/payamsadeghishabestari/KI_MEG/epochs/tinmeg1'\n",
    "epochs_file = {}\n",
    "for f in sorted(os.listdir(epochs_folder)):\n",
    "    file = os.path.join(epochs_folder, f)\n",
    "    if file.endswith(\"-epo.fif\"):\n",
    "        epochs_file[f'{file[-11:-8]}'] = file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create epochs dictionary (some needs concatenating)\n",
    "epochs_folder = '/Users/payamsadeghishabestari/KI_MEG/epochs/tinmeg1'\n",
    "epochs_file = {}\n",
    "for f in sorted(os.listdir(epochs_folder)):\n",
    "    file = os.path.join(epochs_folder, f)\n",
    "    if file.endswith(\"-epo.fif\") and '697' not in file and '750' not in file and '853' not in file:\n",
    "        epochs_file[f'{file[-11:-8]}'] = file\n",
    "\n",
    "# compute evoked objects, and making grand average dictionary\n",
    "evs = []\n",
    "for ep_f in tqdm(list(epochs_file.values())):\n",
    "    evs.append(mne.read_epochs(fname=ep_f, verbose=False).average(picks=['meg', 'eog'], by_event_type=True))\n",
    "\n",
    "grnd_ev_dict = {}\n",
    "for stim_idx, stim in enumerate(list(events_dict_tinmeg1.keys())):\n",
    "    evs_stim = []\n",
    "    for ev in evs:\n",
    "        evs_stim.append(ev[stim_idx])\n",
    "    grnd_ev_dict[stim] = evs_stim\n",
    "\n",
    "grand_ev_dict = {}\n",
    "for stim in list(grnd_ev_dict.keys()):\n",
    "    grand_ev_dict[stim] = mne.grand_average(grnd_ev_dict[stim])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check EOG response (Niklas thesis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### PO at 60 dB\n",
    "fig, axs = plt.subplots(1, 1, figsize=(8, 5))\n",
    "time_array = np.linspace(-300, 300, 151)\n",
    "stims = ['PO60_70', 'PO60_75', 'PO60_80', 'PO60_85', 'PO60_90', 'PO60_95']\n",
    "colors = ['purple', 'brown', 'blue', 'orange', 'red', 'green']\n",
    "for stim, color in zip(stims, colors):\n",
    "    axs.plot(time_array, grand_ev_dict[stim].get_data(picks='EOG002')[0] * 1e6, label=stim)\n",
    "axs.axvspan(50, 220, alpha=0.4, color='lightcyan')\n",
    "axs.legend(fontsize=9, frameon=False)\n",
    "axs.spines['top'].set_visible(False); axs.spines['right'].set_visible(False)\n",
    "axs.grid(axis='x', color='k', linestyle='--', linewidth=0.5)\n",
    "axs.vlines(0, -50, 10, colors='black',linestyles='--')\n",
    "axs.set_ylabel(f'EOG amplitude at 60 dB (µv)')\n",
    "axs.set_xlabel(f'Time (ms)')\n",
    "\n",
    "#### GP at 60 dB\n",
    "fig, axs = plt.subplots(1, 1, figsize=(8, 5))\n",
    "time_array = np.linspace(-300, 300, 151)\n",
    "stims = ['GP60_i0', 'GP60_i60', 'GP60_i120', 'GP60_i240']\n",
    "colors = ['blue', 'orange', 'red', 'green']\n",
    "for stim, color in zip(stims, colors):\n",
    "    axs.plot(time_array, grand_ev_dict[stim].get_data(picks='EOG002')[0] * 1e6, label=stim)\n",
    "axs.axvspan(50, 220, alpha=0.4, color='lightcyan')\n",
    "axs.legend(fontsize=9, frameon=False)\n",
    "axs.spines['top'].set_visible(False); axs.spines['right'].set_visible(False)\n",
    "axs.grid(axis='x', color='k', linestyle='--', linewidth=0.5)\n",
    "axs.vlines(0, -50, 10, colors='black',linestyles='--')\n",
    "axs.set_ylabel(f'EOG amplitude at 60 dB (µv)')\n",
    "axs.set_xlabel(f'Time (ms)')\n",
    "axs.set_xlim([-300, 300])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check ERFs (Niklas thesis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate chanels on left and right\n",
    "info_ch = evs[0][0].info['chs']\n",
    "meg_chs_right = []; meg_chs_left = []\n",
    "grad_chs_right = []; grad_chs_left = []\n",
    "for i in range(len(info_ch)):\n",
    "    if info_ch[i]['unit'] == 112: # meg code\n",
    "        if info_ch[i]['loc'][0] > 0:\n",
    "            meg_chs_right.append(info_ch[i]['ch_name'])\n",
    "        if info_ch[i]['loc'][0] < 0:\n",
    "            meg_chs_left.append(info_ch[i]['ch_name'])\n",
    "    if info_ch[i]['unit'] == 201: # grad code\n",
    "        if info_ch[i]['loc'][0] > 0:\n",
    "            grad_chs_right.append(info_ch[i]['ch_name'])\n",
    "        if info_ch[i]['loc'][0] < 0:\n",
    "            grad_chs_left.append(info_ch[i]['ch_name'])\n",
    "\n",
    "# select the left/ channels with largest ptp amplitude\n",
    "ev_data_left = grand_ev_dict['PO60_70'].get_data(picks=grad_chs_left)\n",
    "ev_data_right = grand_ev_dict['PO60_70'].get_data(picks=grad_chs_right)\n",
    "max_values = []\n",
    "for ch_idx in range(len(ev_data_left)):\n",
    "    max_values.append(ev_data_left[ch_idx][50:150].max())\n",
    "ch_max_left = grad_chs_left[np.argmax(np.array(max_values))]\n",
    "max_values = []\n",
    "for ch_idx in range(len(ev_data_right)):\n",
    "    max_values.append(ev_data_right[ch_idx][50:150].max())\n",
    "ch_max_right = grad_chs_right[np.argmax(np.array(max_values))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PO 60 dB\n",
    "fig, axs = plt.subplots(1, 1, figsize=(10, 3))\n",
    "time_array = np.linspace(-300, 300, 151)\n",
    "stims = ['PO60_70', 'PO60_75', 'PO60_80', 'PO60_85', 'PO60_90', 'PO60_95']\n",
    "alphas = np.linspace(0.2, 1, 6)\n",
    "for stim, alpha in zip(stims, alphas):\n",
    "    axs.plot(time_array, grand_ev_dict[stim].get_data(picks=ch_max_left)[0] * 1e13, color='#1f77b4', alpha=alpha, label=stim)\n",
    "    axs.plot(time_array, grand_ev_dict[stim].get_data(picks=ch_max_right)[0] * 1e13, color='red', alpha=alpha, label=stim)\n",
    "axs.axvspan(50, 150, alpha=0.4, color='lightcyan')\n",
    "axs.spines['top'].set_visible(False); axs.spines['right'].set_visible(False)\n",
    "axs.grid(axis='x', color='k', linestyle='--', linewidth=0.5)\n",
    "axs.set_ylabel(f'ERF amplitude at 60 dB (fT/m)')\n",
    "axs.set_xlabel(f'Time (ms)')\n",
    "axs.set_xlim([-300, 300])\n",
    "\n",
    "# GP 60 dB\n",
    "fig, axs = plt.subplots(1, 1, figsize=(10, 3))\n",
    "time_array = np.linspace(-300, 300, 151)\n",
    "stims = ['GP60_i0', 'GP60_i60', 'GP60_i120', 'GP60_i240']\n",
    "dc_shifts = [0, 50, 100, 150]\n",
    "for stim, dc_shift in zip(stims, dc_shifts):\n",
    "    axs.plot(time_array, dc_shift + grand_ev_dict[stim].get_data(picks=ch_max_left)[0] * 1e13, color='#1f77b4', label=stim)\n",
    "    axs.plot(time_array, dc_shift + grand_ev_dict[stim].get_data(picks=ch_max_right)[0] * 1e13, color='red', label=stim)\n",
    "axs.axvspan(50, 150, alpha=0.4, color='lightcyan')\n",
    "axs.spines['top'].set_visible(False); axs.spines['right'].set_visible(False)\n",
    "axs.grid(axis='x', color='k', linestyle='--', linewidth=0.5)\n",
    "axs.set_ylabel(f'Relative values')\n",
    "axs.set_xlabel(f'Time (ms)')\n",
    "axs.set_xlim([-300, 300])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source Localization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some Notes:\n",
    "# 1. check with and without ICA, since we didnt remove blink, however makes sense to proceed without applying ICA\n",
    "# 2. before the time 0, we have an activity at GP series so its not a good idea to use epochs baseline as a time span to estimate noise covariance\n",
    "# the good way to estimate the noise cov is to use only PO series baseline   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cortical surface reconstruction (+bem, +head_model) with FreeSurfer (as an example for one subject)\n",
    "$ export FREESURFER_HOME=/Applications/freesurfer/7.4.1\n",
    "$ export SUBJECTS_DIR=$FREESURFER_HOME/subjects\n",
    "$ source $FREESURFER_HOME/SetUpFreeSurfer.sh\n",
    "$ recon-all -s 0863 -i /Users/payamsadeghishabestari/KI_MEG/MRI/0863/00000003/00000001.dcm \n",
    "$ recon-all -all -subjid 0863\n",
    "\n",
    "# setting up watershed BEM files \n",
    "subject = '0863'\n",
    "subjects_dir = '/Applications/freesurfer/7.4.1/subjects'\n",
    "mne.bem.make_watershed_bem(subject, subjects_dir=None,\n",
    "                            overwrite=False, volume='T1', atlas=False,\n",
    "                            gcaatlas=False, preflood=None, show=False,\n",
    "                            copy=True, T1=None, brainmask='ws.mgz', verbose=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# po_stims = ['PO60_70', 'PO60_75', 'PO60_80', 'PO60_85', 'PO60_90', 'PO60_95'] # for tinmeg1\n",
    "po_stims = ['PO_00', 'PPP_00', 'PO_03', 'PO_08'] # tinmeg3\n",
    "# po_stims = ['PO_00', 'PO_03', 'PO_08', 'PO_30', 'PO_33', 'PO_38', 'PO_80', 'PO_83', 'PO_88'] # tinmeg2\n",
    "\n",
    "subjects_dir = '/Applications/freesurfer/7.4.1/subjects'\n",
    "method = \"dSPM\"\n",
    "snr = 3.0\n",
    "lambda2 = 1.0 / snr**2\n",
    "\n",
    "for subject in np.array(list(epochs_file.keys()))[[11,12]]: # list(epochs_file.keys())\n",
    "    \n",
    "    subject_idx = list(epochs_file.keys()).index(subject)\n",
    "    report = mne.Report(title=f'source_localization_report_subject_{subject}', verbose=False)\n",
    "    \n",
    "    # Setting up the surface source space\n",
    "    print(f'Setting up bilateral hemisphere surface-based source space with subsampling for subject {subject} ...')\n",
    "    src = mne.setup_source_space(f'{subject}', spacing=\"oct6\", subjects_dir=subjects_dir, n_jobs=-1, verbose=None)\n",
    "\n",
    "    # Setting up the boundary-element model (BEM) \n",
    "    print(f'Creating a BEM model for subject ...')\n",
    "    bem_model = mne.make_bem_model(subject=f'{subject}', ico=4, subjects_dir=subjects_dir, verbose=False)  \n",
    "    bem = mne.make_bem_solution(bem_model, verbose=False)\n",
    "    report.add_bem(subject=f'{subject}', subjects_dir=subjects_dir, title=\"MRI & BEM\", decim=10, width=512)\n",
    "\n",
    "    # Aligning coordinate frame (coregistration MEG-MRI)\n",
    "    print(f'Coregistering MRI with a subjects head shape ...')\n",
    "    # info = grnd_ev_dict['PO60_80'][subject_idx].info # tinmeg1\n",
    "    info = grnd_ev_dict['PO_00'][subject_idx].info # tinmeg3\n",
    "    coreg = Coregistration(info, f'{subject}', subjects_dir, fiducials='auto')\n",
    "    coreg.fit_fiducials(verbose=False)\n",
    "    coreg.fit_icp(n_iterations=40, nasion_weight=2.0, verbose=False) # refining with ICP\n",
    "    coreg.omit_head_shape_points(distance=5.0 / 1000) # omitting bad points (larger than 5mm)\n",
    "    coreg.fit_icp(n_iterations=40, nasion_weight=10, verbose=False) # final fitting\n",
    "    fname_trans = f'/Users/payamsadeghishabestari/KI_MEG/trans/{subject}-trans.fif'\n",
    "    mne.write_trans(fname_trans, coreg.trans, overwrite=True, verbose=False)\n",
    "    report.add_trans(trans=fname_trans, info=info, subject=f'{subject}',\n",
    "                    subjects_dir=subjects_dir, alpha=1.0, title=\"Co-registration\")\n",
    "\n",
    "    # Computing the forward solution\n",
    "    print(f'Computing the forward solution ...')\n",
    "    fwd = mne.make_forward_solution(info, trans=coreg.trans, src=src, bem=bem, meg=True,\n",
    "                                    eeg=False, mindist=5.0, n_jobs=None, verbose=False)\n",
    "\n",
    "    # Computing the regularized noise-covariance matrix (consider the notes)\n",
    "    print(f'Estimate the noise covariance of the recording ...')\n",
    "    epochs = mne.read_epochs(fname=epochs_file[subject], verbose=False)\n",
    "    noise_cov = mne.compute_covariance(epochs[po_stims], tmax=0.0, method=(\"empirical\", \"shrunk\"),\n",
    "                                        verbose=False) # using the epochs baseline \n",
    "    \n",
    "    # Computing the minimum-norm inverse solution\n",
    "    print(f'Computing the minimum-norm inverse solution ...')\n",
    "    inverse_operator = make_inverse_operator(info, fwd, noise_cov, loose=0.2, depth=0.8, verbose=False)\n",
    "\n",
    "    # Compute source estimate object\n",
    "    print(f'Computing and saving the source estimate object ...')\n",
    "    for key_id in list(grnd_ev_dict.keys()):\n",
    "        stc = apply_inverse(grnd_ev_dict[key_id][subject_idx], inverse_operator, lambda2, method=method, pick_ori=None,\n",
    "                            return_residual=False, verbose=False)\n",
    "        fname_stc = f'/Users/payamsadeghishabestari/KI_MEG/stcs/tinmeg3/{subject}_{key_id}'\n",
    "        stc.save(fname=fname_stc, overwrite=True, verbose=False)\n",
    "\n",
    "    # saving report\n",
    "    fname_report = f'/Users/payamsadeghishabestari/KI_MEG/reports/source_localization_report_subject_{subject}.html'\n",
    "    report.save(fname=fname_report, open_browser=False, overwrite=True, verbose=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Morphing to freesurfer template brain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects_dir = '/Applications/freesurfer/7.4.1/subjects'\n",
    "fname_fsaverage_src = '/Users/payamsadeghishabestari/mne_data/MNE-fsaverage-data/fsaverage/bem/fsaverage-ico-5-src.fif'\n",
    "directory = '/Users/payamsadeghishabestari/KI_MEG/stcs/tinmeg3' \n",
    "src_to = mne.read_source_spaces(fname_fsaverage_src)\n",
    "\n",
    "# iterate over files in that directory\n",
    "stc_files_list = []\n",
    "for filename in sorted(os.listdir(directory)): \n",
    "    f = os.path.join(directory, filename)\n",
    "    # checking if it is a file\n",
    "    if os.path.isfile(f) and f.endswith(\"-lh.stc\"): # or -rh\n",
    "        stc_files_list.append(f)\n",
    "\n",
    "# morphing from oct-6 to ico-5 at fsaverage\n",
    "for stc_file in tqdm(stc_files_list):\n",
    "    stc = mne.read_source_estimate(fname=stc_file, subject=f'{stc_file[50:54]}')\n",
    "    \n",
    "    morph = mne.compute_source_morph(stc, subject_from=f'{stc_file[50:54]}',\n",
    "                                    subject_to=\"fsaverage\", subjects_dir=subjects_dir,\n",
    "                                    src_to=src_to)\n",
    "    stc_morph = morph.apply(stc)\n",
    "    fname_stc_morph = ''.join([stc_file[:49], '_morphed', stc_file[49:]])\n",
    "    stc_morph.save(fname=fname_stc_morph, overwrite=True, verbose=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualization example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# single subject\n",
    "subject = '859'\n",
    "event = 'PO60_90'\n",
    "fname_stc = f'/Users/payamsadeghishabestari/KI_MEG/stcs/tinmeg1/{subject}_{event}-rh.stc'\n",
    "stc = mne.read_source_estimate(fname=fname_stc, subject=f'0{subject}')\n",
    "subjects_dir = '/Applications/freesurfer/7.4.1/subjects'\n",
    "colormap = \"viridis\"\n",
    "clim = dict(kind=\"value\", lims=[4, 8, 12])\n",
    "fig_brain = stc.plot(views=\"lat\", hemi=\"split\", size=(800, 400), subject=f'0{subject}',\n",
    "                    subjects_dir=subjects_dir, background=\"w\", colorbar=True, clim=clim,\n",
    "                    colormap=colormap, time_viewer=True, show_traces=True)\n",
    "fig_brain.add_annotation(\"aparc\", borders=True, alpha=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# average of subjects\n",
    "event = 'GO_60'\n",
    "directory = '/Users/payamsadeghishabestari/KI_MEG/stcs/tinmeg1_morphed'\n",
    "stc_files_list = []\n",
    "for filename in sorted(os.listdir(directory)): \n",
    "    f = os.path.join(directory, filename)\n",
    "    # checking if it is a file\n",
    "    if os.path.isfile(f) and f.endswith(\"-lh.stc\") and (event in f): # or -rh\n",
    "        stc_files_list.append(f)\n",
    "data = []\n",
    "for stc_file in tqdm(stc_files_list):\n",
    "    stc = mne.read_source_estimate(fname=stc_file, subject='fsaverage')\n",
    "    data.append(stc.data)\n",
    "stc_average = mne.SourceEstimate(data=np.mean(np.array(data), axis=0), vertices=stc.vertices,\n",
    "                                tmin=stc.tmin, tstep=stc.tstep, subject='fsaverage')\n",
    "colormap = \"viridis\"\n",
    "clim = dict(kind=\"value\", lims=[4, 8, 12])\n",
    "fig_brain = stc_average.plot(views=\"lat\", hemi=\"split\", size=(800, 400), subject='fsaverage',\n",
    "                    subjects_dir=None, background=\"w\", colorbar=True, clim=clim,\n",
    "                    colormap=colormap, time_viewer=True, show_traces=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# average of subjects\n",
    "event1 = 'PO60_90'\n",
    "event2 = 'GO_60'\n",
    "event3 = 'GP60_i0'\n",
    "event4 = 'GP60_i60'\n",
    "event5 = 'GP60_i120'\n",
    "event6 = 'GP60_i240'\n",
    "subject = '853'\n",
    "\n",
    "directory = '/Users/payamsadeghishabestari/KI_MEG/stcs/tinmeg1_morphed'\n",
    "stc_files_list_1 = []; stc_files_list_2 = []; stc_files_list_3 = []; stc_files_list_4 = []; stc_files_list_5 = []; stc_files_list_6 = []\n",
    "for filename in sorted(os.listdir(directory)): \n",
    "    f = os.path.join(directory, filename)\n",
    "    # checking if it is a file\n",
    "    if os.path.isfile(f) and f.endswith(\"-lh.stc\") and (event1 in f) and (subject in f): # or -rh\n",
    "        stc_files_list_1.append(f)\n",
    "    if os.path.isfile(f) and f.endswith(\"-lh.stc\") and (event2 in f) and (subject in f): # or -rh\n",
    "        stc_files_list_2.append(f)\n",
    "    if os.path.isfile(f) and f.endswith(\"-lh.stc\") and (event3 in f) and (subject in f): # or -rh\n",
    "        stc_files_list_3.append(f)\n",
    "    if os.path.isfile(f) and f.endswith(\"-lh.stc\") and (event4 in f) and (subject in f): # or -rh\n",
    "        stc_files_list_4.append(f)\n",
    "    if os.path.isfile(f) and f.endswith(\"-lh.stc\") and (event5 in f) and (subject in f): # or -rh\n",
    "        stc_files_list_5.append(f)\n",
    "    if os.path.isfile(f) and f.endswith(\"-lh.stc\") and (event6 in f) and (subject in f): # or -rh\n",
    "        stc_files_list_6.append(f)\n",
    "\n",
    "fig, axs = plt.subplots(1, 6, figsize=(17, 2))\n",
    "ymax = 4\n",
    "data_lh = []\n",
    "data_rh = []\n",
    "for stc_file in tqdm(stc_files_list_1):\n",
    "    stc = mne.read_source_estimate(fname=stc_file, subject='fsaverage')\n",
    "    data_lh.append(stc.lh_data)\n",
    "    data_rh.append(stc.rh_data)\n",
    "\n",
    "axs[0].plot(stc.times*1000, np.mean(np.mean(data_lh, axis=0), axis=0).T, color='#1f77b4')\n",
    "axs[0].plot(stc.times*1000, np.mean(np.mean(data_rh, axis=0), axis=0).T, color='#ff7f0e')\n",
    "axs[0].grid(axis='x'); axs[0].set_ylim([0, ymax])\n",
    "\n",
    "data_lh = []\n",
    "data_rh = []\n",
    "for stc_file in tqdm(stc_files_list_2):\n",
    "    stc = mne.read_source_estimate(fname=stc_file, subject='fsaverage')\n",
    "    data_lh.append(stc.lh_data)\n",
    "    data_rh.append(stc.rh_data)\n",
    "\n",
    "axs[1].plot(stc.times*1000, np.mean(np.mean(data_lh, axis=0), axis=0).T, color='#1f77b4')\n",
    "axs[1].plot(stc.times*1000, np.mean(np.mean(data_rh, axis=0), axis=0).T, color='#ff7f0e')\n",
    "axs[1].grid(axis='x'); axs[1].set_ylim([0, ymax])\n",
    "\n",
    "data_lh = []\n",
    "data_rh = []\n",
    "for stc_file in tqdm(stc_files_list_3):\n",
    "    stc = mne.read_source_estimate(fname=stc_file, subject='fsaverage')\n",
    "    data_lh.append(stc.lh_data)\n",
    "    data_rh.append(stc.rh_data)\n",
    "\n",
    "axs[2].plot(stc.times*1000, np.mean(np.mean(data_lh, axis=0), axis=0).T, color='#1f77b4')\n",
    "axs[2].plot(stc.times*1000, np.mean(np.mean(data_rh, axis=0), axis=0).T, color='#ff7f0e')\n",
    "axs[2].grid(axis='x'); axs[2].set_ylim([0, ymax])\n",
    "\n",
    "data_lh = []\n",
    "data_rh = []\n",
    "for stc_file in tqdm(stc_files_list_4):\n",
    "    stc = mne.read_source_estimate(fname=stc_file, subject='fsaverage')\n",
    "    data_lh.append(stc.lh_data)\n",
    "    data_rh.append(stc.rh_data)\n",
    "\n",
    "axs[3].plot(stc.times*1000, np.mean(np.mean(data_lh, axis=0), axis=0).T, color='#1f77b4')\n",
    "axs[3].plot(stc.times*1000, np.mean(np.mean(data_rh, axis=0), axis=0).T, color='#ff7f0e')\n",
    "axs[3].grid(axis='x'); axs[3].set_ylim([0, ymax])\n",
    "\n",
    "data_lh = []\n",
    "data_rh = []\n",
    "for stc_file in tqdm(stc_files_list_5):\n",
    "    stc = mne.read_source_estimate(fname=stc_file, subject='fsaverage')\n",
    "    data_lh.append(stc.lh_data)\n",
    "    data_rh.append(stc.rh_data)\n",
    "\n",
    "axs[4].plot(stc.times*1000, np.mean(np.mean(data_lh, axis=0), axis=0).T, color='#1f77b4')\n",
    "axs[4].plot(stc.times*1000, np.mean(np.mean(data_rh, axis=0), axis=0).T, color='#ff7f0e')\n",
    "axs[4].grid(axis='x'); axs[4].set_ylim([0, ymax])\n",
    "\n",
    "data_lh = []\n",
    "data_rh = []\n",
    "for stc_file in tqdm(stc_files_list_6):\n",
    "    stc = mne.read_source_estimate(fname=stc_file, subject='fsaverage')\n",
    "    data_lh.append(stc.lh_data)\n",
    "    data_rh.append(stc.rh_data)\n",
    "\n",
    "axs[5].plot(stc.times*1000, np.mean(np.mean(data_lh, axis=0), axis=0).T, color='#1f77b4')\n",
    "axs[5].plot(stc.times*1000, np.mean(np.mean(data_rh, axis=0), axis=0).T, color='#ff7f0e')\n",
    "axs[5].grid(axis='x'); axs[5].set_ylim([0, ymax])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting all subjects * conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject = '853'\n",
    "directory = '/Users/payamsadeghishabestari/KI_MEG/stcs/tinmeg1_morphed'\n",
    "stc_files_list = []\n",
    "for filename in sorted(os.listdir(directory)): \n",
    "    f = os.path.join(directory, filename)\n",
    "    # checking if it is a file\n",
    "    if os.path.isfile(f) and f.endswith(\"-lh.stc\") and (subject in f): # or -rh\n",
    "        stc_files_list.append(f)\n",
    "\n",
    "event1 = 'PO60_90'\n",
    "event2 = 'GO_60'\n",
    "event3 = 'GP60_i0'\n",
    "event4 = 'GP60_i60'\n",
    "event5 = 'GP60_i120'\n",
    "event6 = 'GP60_i240'\n",
    "fig, axs = plt.subplots(1, 6, figsize=(17, 2))\n",
    "ymax = 5\n",
    "for stc_file in stc_files_list:\n",
    "    if event1 in stc_file:\n",
    "        stc = mne.read_source_estimate(fname=stc_file, subject='fsaverage')\n",
    "        axs[0].plot(stc.times*1000, np.mean(stc.lh_data, axis=0).T, color='#1f77b4')\n",
    "        axs[0].plot(stc.times*1000, np.mean(stc.rh_data, axis=0).T, color='#ff7f0e')\n",
    "        axs[0].grid(axis='x'); axs[0].set_ylim([0, ymax])\n",
    "    if event2 in stc_file:\n",
    "        stc = mne.read_source_estimate(fname=stc_file, subject='fsaverage')\n",
    "        axs[1].plot(stc.times*1000, np.mean(stc.lh_data, axis=0).T, color='#1f77b4')\n",
    "        axs[1].plot(stc.times*1000, np.mean(stc.rh_data, axis=0).T, color='#ff7f0e')\n",
    "        axs[1].grid(axis='x'); axs[1].set_ylim([0, ymax])\n",
    "    if event3 in stc_file:\n",
    "        stc = mne.read_source_estimate(fname=stc_file, subject='fsaverage')\n",
    "        axs[2].plot(stc.times*1000, np.mean(stc.lh_data, axis=0).T, color='#1f77b4')\n",
    "        axs[2].plot(stc.times*1000, np.mean(stc.rh_data, axis=0).T, color='#ff7f0e')\n",
    "        axs[2].grid(axis='x'); axs[2].set_ylim([0, ymax])\n",
    "    if event4 in stc_file:\n",
    "        stc = mne.read_source_estimate(fname=stc_file, subject='fsaverage')\n",
    "        axs[3].plot(stc.times*1000, np.mean(stc.lh_data, axis=0).T, color='#1f77b4')\n",
    "        axs[3].plot(stc.times*1000, np.mean(stc.rh_data, axis=0).T, color='#ff7f0e')\n",
    "        axs[3].grid(axis='x'); axs[3].set_ylim([0, ymax])\n",
    "    if event5 in stc_file:\n",
    "        stc = mne.read_source_estimate(fname=stc_file, subject='fsaverage')\n",
    "        axs[4].plot(stc.times*1000, np.mean(stc.lh_data, axis=0).T, color='#1f77b4')\n",
    "        axs[4].plot(stc.times*1000, np.mean(stc.rh_data, axis=0).T, color='#ff7f0e')\n",
    "        axs[4].grid(axis='x'); axs[4].set_ylim([0, ymax])\n",
    "    if event6 in stc_file:\n",
    "        stc = mne.read_source_estimate(fname=stc_file, subject='fsaverage')\n",
    "        axs[5].plot(stc.times*1000, np.mean(stc.lh_data, axis=0).T, color='#1f77b4')\n",
    "        axs[5].plot(stc.times*1000, np.mean(stc.rh_data, axis=0).T, color='#ff7f0e')\n",
    "        axs[5].grid(axis='x'); axs[5].set_ylim([0, ymax])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting time courses in transverstemporal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject = '863'\n",
    "directory = '/Users/payamsadeghishabestari/KI_MEG/stcs/tinmeg1_morphed'\n",
    "stc_files_list = []\n",
    "for filename in sorted(os.listdir(directory)): \n",
    "    f = os.path.join(directory, filename)\n",
    "    # checking if it is a file\n",
    "    if os.path.isfile(f) and f.endswith(\"-lh.stc\") and (subject in f): # or -rh\n",
    "        stc_files_list.append(f)\n",
    "\n",
    "event1 = 'PO60_90'\n",
    "event2 = 'GO_60'\n",
    "event3 = 'GP60_i0'\n",
    "event4 = 'GP60_i60'\n",
    "event5 = 'GP60_i120'\n",
    "event6 = 'GP60_i240'\n",
    "\n",
    "brain_labels = mne.read_labels_from_annot(subject='fsaverage', parc='aparc')[:-1] # 68 labels\n",
    "fs_dir = fetch_fsaverage(verbose=False)\n",
    "src_fname = op.join(fs_dir, \"bem\", \"fsaverage-ico-5-src.fif\")\n",
    "src = mne.read_source_spaces(src_fname, verbose=False)\n",
    "bl_idx_rh = -1\n",
    "bl_idx_lh = -2\n",
    "mode = 'mean'\n",
    "\n",
    "fig, axs = plt.subplots(1, 6, figsize=(17, 2))\n",
    "ymax = 12\n",
    "for stc_file in stc_files_list:\n",
    "    if event1 in stc_file:\n",
    "        stc = mne.read_source_estimate(fname=stc_file, subject='fsaverage')\n",
    "        stc_rh = stc.extract_label_time_course(brain_labels[bl_idx_rh], src, mode=mode, verbose=False)\n",
    "        stc_lh = stc.extract_label_time_course(brain_labels[bl_idx_lh], src, mode=mode, verbose=False)\n",
    "        axs[0].plot(stc.times*1000, stc_rh[0], color='#1f77b4')\n",
    "        axs[0].plot(stc.times*1000, stc_lh[0], color='#ff7f0e')\n",
    "        axs[0].grid(axis='x'); axs[0].set_ylim([0, ymax])\n",
    "    if event2 in stc_file:\n",
    "        stc = mne.read_source_estimate(fname=stc_file, subject='fsaverage')\n",
    "        stc_rh = stc.extract_label_time_course(brain_labels[bl_idx_rh], src, mode=mode, verbose=False)\n",
    "        stc_lh = stc.extract_label_time_course(brain_labels[bl_idx_lh], src, mode=mode, verbose=False)\n",
    "        axs[1].plot(stc.times*1000, stc_rh[0], color='#1f77b4')\n",
    "        axs[1].plot(stc.times*1000, stc_lh[0], color='#ff7f0e')\n",
    "        axs[1].grid(axis='x'); axs[1].set_ylim([0, ymax])\n",
    "    if event3 in stc_file:\n",
    "        stc = mne.read_source_estimate(fname=stc_file, subject='fsaverage')\n",
    "        stc_rh = stc.extract_label_time_course(brain_labels[bl_idx_rh], src, mode=mode, verbose=False)\n",
    "        stc_lh = stc.extract_label_time_course(brain_labels[bl_idx_lh], src, mode=mode, verbose=False)\n",
    "        axs[2].plot(stc.times*1000, stc_rh[0], color='#1f77b4')\n",
    "        axs[2].plot(stc.times*1000, stc_lh[0], color='#ff7f0e')\n",
    "        axs[2].grid(axis='x'); axs[2].set_ylim([0, ymax])\n",
    "    if event4 in stc_file:\n",
    "        stc = mne.read_source_estimate(fname=stc_file, subject='fsaverage')\n",
    "        stc_rh = stc.extract_label_time_course(brain_labels[bl_idx_rh], src, mode=mode, verbose=False)\n",
    "        stc_lh = stc.extract_label_time_course(brain_labels[bl_idx_lh], src, mode=mode, verbose=False)\n",
    "        axs[3].plot(stc.times*1000, stc_rh[0], color='#1f77b4')\n",
    "        axs[3].plot(stc.times*1000, stc_lh[0], color='#ff7f0e')\n",
    "        axs[3].grid(axis='x'); axs[3].set_ylim([0, ymax])\n",
    "    if event5 in stc_file:\n",
    "        stc = mne.read_source_estimate(fname=stc_file, subject='fsaverage')\n",
    "        stc_rh = stc.extract_label_time_course(brain_labels[bl_idx_rh], src, mode=mode, verbose=False)\n",
    "        stc_lh = stc.extract_label_time_course(brain_labels[bl_idx_lh], src, mode=mode, verbose=False)\n",
    "        axs[4].plot(stc.times*1000, stc_rh[0], color='#1f77b4')\n",
    "        axs[4].plot(stc.times*1000, stc_lh[0], color='#ff7f0e')\n",
    "        axs[4].grid(axis='x'); axs[4].set_ylim([0, ymax])\n",
    "    if event6 in stc_file:\n",
    "        stc = mne.read_source_estimate(fname=stc_file, subject='fsaverage')\n",
    "        stc_rh = stc.extract_label_time_course(brain_labels[bl_idx_rh], src, mode=mode, verbose=False)\n",
    "        stc_lh = stc.extract_label_time_course(brain_labels[bl_idx_lh], src, mode=mode, verbose=False)\n",
    "        axs[5].plot(stc.times*1000, stc_rh[0], color='#1f77b4')\n",
    "        axs[5].plot(stc.times*1000, stc_lh[0], color='#ff7f0e')\n",
    "        axs[5].grid(axis='x'); axs[5].set_ylim([0, ymax])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# average in transtemporal\n",
    "subject = '863'\n",
    "directory = '/Users/payamsadeghishabestari/KI_MEG/stcs/tinmeg1_morphed'\n",
    "stc_files_list = []\n",
    "for filename in sorted(os.listdir(directory)): \n",
    "    f = os.path.join(directory, filename)\n",
    "    # checking if it is a file\n",
    "    if os.path.isfile(f) and f.endswith(\"-lh.stc\"): # or -rh\n",
    "        stc_files_list.append(f)\n",
    "\n",
    "event1 = 'PO60_90'\n",
    "event2 = 'GO_60'\n",
    "event3 = 'GP60_i0'\n",
    "event4 = 'GP60_i60'\n",
    "event5 = 'GP60_i120'\n",
    "event6 = 'GP60_i240'\n",
    "\n",
    "brain_labels = mne.read_labels_from_annot(subject='fsaverage', parc='aparc')[:-1] # 68 labels\n",
    "fs_dir = fetch_fsaverage(verbose=False)\n",
    "src_fname = op.join(fs_dir, \"bem\", \"fsaverage-ico-5-src.fif\")\n",
    "src = mne.read_source_spaces(src_fname, verbose=False)\n",
    "bl_idx_rh = -1\n",
    "bl_idx_lh = -2\n",
    "mode = 'mean'\n",
    "\n",
    "fig, axs = plt.subplots(1, 6, figsize=(17, 2))\n",
    "ymax = 12\n",
    "stcs_rh_1 = []; stcs_lh_1 = []\n",
    "stcs_rh_2 = []; stcs_lh_2 = []\n",
    "stcs_rh_3 = []; stcs_lh_3 = []\n",
    "stcs_rh_4 = []; stcs_lh_4 = []\n",
    "stcs_rh_5 = []; stcs_lh_5 = []\n",
    "stcs_rh_6 = []; stcs_lh_6 = []\n",
    "\n",
    "for stc_file in stc_files_list:\n",
    "    if event1 in stc_file:\n",
    "        stc = mne.read_source_estimate(fname=stc_file, subject='fsaverage')\n",
    "        stcs_rh_1.append(stc.extract_label_time_course(brain_labels[bl_idx_rh], src, mode=mode, verbose=False))\n",
    "        stcs_lh_1.append(stc.extract_label_time_course(brain_labels[bl_idx_lh], src, mode=mode, verbose=False))\n",
    "    if event2 in stc_file:\n",
    "        stc = mne.read_source_estimate(fname=stc_file, subject='fsaverage')\n",
    "        stcs_rh_2.append(stc.extract_label_time_course(brain_labels[bl_idx_rh], src, mode=mode, verbose=False))\n",
    "        stcs_lh_2.append(stc.extract_label_time_course(brain_labels[bl_idx_lh], src, mode=mode, verbose=False))\n",
    "    if event3 in stc_file:\n",
    "        stc = mne.read_source_estimate(fname=stc_file, subject='fsaverage')\n",
    "        stcs_rh_3.append(stc.extract_label_time_course(brain_labels[bl_idx_rh], src, mode=mode, verbose=False))\n",
    "        stcs_lh_3.append(stc.extract_label_time_course(brain_labels[bl_idx_lh], src, mode=mode, verbose=False))\n",
    "    if event4 in stc_file:\n",
    "        stc = mne.read_source_estimate(fname=stc_file, subject='fsaverage')\n",
    "        stcs_rh_4.append(stc.extract_label_time_course(brain_labels[bl_idx_rh], src, mode=mode, verbose=False))\n",
    "        stcs_lh_4.append(stc.extract_label_time_course(brain_labels[bl_idx_lh], src, mode=mode, verbose=False))\n",
    "    if event5 in stc_file:\n",
    "        stc = mne.read_source_estimate(fname=stc_file, subject='fsaverage')\n",
    "        stcs_rh_5.append(stc.extract_label_time_course(brain_labels[bl_idx_rh], src, mode=mode, verbose=False))\n",
    "        stcs_lh_5.append(stc.extract_label_time_course(brain_labels[bl_idx_lh], src, mode=mode, verbose=False))\n",
    "    if event6 in stc_file:\n",
    "        stc = mne.read_source_estimate(fname=stc_file, subject='fsaverage')\n",
    "        stcs_rh_6.append(stc.extract_label_time_course(brain_labels[bl_idx_rh], src, mode=mode, verbose=False))\n",
    "        stcs_lh_6.append(stc.extract_label_time_course(brain_labels[bl_idx_lh], src, mode=mode, verbose=False))\n",
    "\n",
    "\n",
    "axs[0].plot(stc.times*1000, np.mean(np.array(stcs_rh_1),axis=0)[0], color='#1f77b4')\n",
    "axs[0].plot(stc.times*1000, np.mean(np.array(stcs_lh_1),axis=0)[0], color='#ff7f0e')\n",
    "axs[0].grid(axis='x'); axs[0].set_ylim([0, ymax])\n",
    "axs[1].plot(stc.times*1000, np.mean(np.array(stcs_rh_2),axis=0)[0], color='#1f77b4')\n",
    "axs[1].plot(stc.times*1000, np.mean(np.array(stcs_lh_2),axis=0)[0], color='#ff7f0e')\n",
    "axs[1].grid(axis='x'); axs[1].set_ylim([0, ymax])\n",
    "axs[2].plot(stc.times*1000, np.mean(np.array(stcs_rh_3),axis=0)[0], color='#1f77b4')\n",
    "axs[2].plot(stc.times*1000, np.mean(np.array(stcs_lh_3),axis=0)[0], color='#ff7f0e')\n",
    "axs[2].grid(axis='x'); axs[2].set_ylim([0, ymax])\n",
    "axs[3].plot(stc.times*1000, np.mean(np.array(stcs_rh_4),axis=0)[0], color='#1f77b4')\n",
    "axs[3].plot(stc.times*1000, np.mean(np.array(stcs_lh_4),axis=0)[0], color='#ff7f0e')\n",
    "axs[3].grid(axis='x'); axs[3].set_ylim([0, ymax])\n",
    "axs[4].plot(stc.times*1000, np.mean(np.array(stcs_rh_5),axis=0)[0], color='#1f77b4')\n",
    "axs[4].plot(stc.times*1000, np.mean(np.array(stcs_lh_5),axis=0)[0], color='#ff7f0e')\n",
    "axs[4].grid(axis='x'); axs[4].set_ylim([0, ymax])\n",
    "axs[5].plot(stc.times*1000, np.mean(np.array(stcs_rh_6),axis=0)[0], color='#1f77b4')\n",
    "axs[5].plot(stc.times*1000, np.mean(np.array(stcs_lh_6),axis=0)[0], color='#ff7f0e')\n",
    "axs[5].grid(axis='x'); axs[5].set_ylim([0, ymax])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test if the evoked response is significantly different between two conditions across subjects\n",
    "event_1 = 'PO70_95'\n",
    "event_2 = 'GP70_i240'\n",
    "\n",
    "# iterate over files, reading files and check\n",
    "directory = '/Users/payamsadeghishabestari/KI_MEG/stcs/tinmeg1_morphed'\n",
    "stc_files_list_ev_1 = []\n",
    "stc_files_list_ev_2 = []\n",
    "for filename in sorted(os.listdir(directory)): \n",
    "    f = os.path.join(directory, filename)\n",
    "    if os.path.isfile(f) and f.endswith(\"-lh.stc\"): # or -rh\n",
    "        if event_1 in f:\n",
    "            stc_files_list_ev_1.append(f)\n",
    "        if event_2 in f:\n",
    "            stc_files_list_ev_2.append(f)\n",
    "\n",
    "if len(stc_files_list_ev_1) == len(stc_files_list_ev_2):\n",
    "    n_subjects = len(stc_files_list_ev_2)\n",
    "else:\n",
    "    raise ValueError('number of subjects for two events are not same')\n",
    "\n",
    "data_ev_1 = []\n",
    "data_ev_2 = []\n",
    "for stc_file_ev_1, stc_file_ev_2 in zip(stc_files_list_ev_1, stc_files_list_ev_2):\n",
    "    stc_ev1 = mne.read_source_estimate(fname=stc_file_ev_1, subject='fsaverage')\n",
    "    stc_ev2 = mne.read_source_estimate(fname=stc_file_ev_2, subject='fsaverage')\n",
    "    data_ev_1.append(stc_ev1.data)\n",
    "    data_ev_2.append(stc_ev2.data)\n",
    "\n",
    "# Creating the big matrix\n",
    "n_vertices, n_times = stc_ev1.data.shape\n",
    "tmin = stc_ev1.tmin\n",
    "tstep = stc_ev1.tstep * 1000 \n",
    "np.random.seed(0)\n",
    "X = np.zeros((n_vertices, n_times, n_subjects, 2))\n",
    "\n",
    "for condition_idx, condition in enumerate(data_ev_1):\n",
    "    X[:, :, condition_idx, 0] += condition\n",
    "for condition_idx, condition in enumerate(data_ev_2):\n",
    "    X[:, :, condition_idx, 1] += condition\n",
    "\n",
    "X = np.abs(X)  \n",
    "X = X[:, :, :, 0] - X[:, :, :, 1] \n",
    "X = np.transpose(X, [2, 1, 0]) # observations (subjects) × time × space\n",
    "\n",
    "# compute adjacency matrix\n",
    "src_fname = '/Users/payamsadeghishabestari/mne_data/MNE-fsaverage-data/fsaverage/bem/fsaverage-ico-5-src.fif'\n",
    "src = mne.read_source_spaces(src_fname, verbose=False)\n",
    "fsave_vertices = [s[\"vertno\"] for s in src]\n",
    "adjacency = mne.spatial_src_adjacency(src, verbose=False)\n",
    "\n",
    "# cluster forming threshold based on a p-value (two-tailed test)\n",
    "p_threshold = 0.001\n",
    "df = n_subjects - 1  \n",
    "n_permutations = 1024\n",
    "t_threshold = stats.distributions.t.ppf(1 - p_threshold / 2, df=df)\n",
    "T_obs, clusters, cluster_p_values, H0 = clu = spatio_temporal_cluster_1samp_test(\n",
    "                                                X, threshold=t_threshold,\n",
    "                                                n_permutations=n_permutations, adjacency=adjacency,\n",
    "                                                n_jobs=-1, verbose=True)\n",
    "\n",
    "# Select the clusters that are statistically significant at p < 0.05\n",
    "good_clusters_idx = np.where(cluster_p_values < 0.05)[0]\n",
    "good_clusters = [clusters[idx] for idx in good_clusters_idx]\n",
    "\n",
    "# Visualize the clusters (blue blobs are for event 1 < event 2, red for event 1 > event 2)\n",
    "colormap = \"auto\"\n",
    "clim = dict(kind=\"value\", lims=[0, 1, 40])\n",
    "stc_all_cluster_vis = summarize_clusters_stc(clu, tstep=tstep, subject=\"fsaverage\", vertices=fsave_vertices)\n",
    "brain = stc_all_cluster_vis.plot(views=\"lat\", hemi=\"split\", size=(800, 400), subject='fsaverage',\n",
    "                    subjects_dir=None, background=\"w\", colorbar=True, clim=clim, colormap=colormap, \n",
    "                    time_label=\"temporal extent (ms)\", time_viewer=True, show_traces=True, smoothing_steps=4)\n",
    "\n",
    "# ***** The first time point in this SourceEstimate object is the summation of all the clusters.\n",
    "#       Subsequent time points contain each individual cluster.\n",
    "#       The magnitude of the activity corresponds to the duration spanned by the cluster *****"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from Source to Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking only one example (also checking different modes)\n",
    "stc_fname = '/Users/payamsadeghishabestari/KI_MEG/stcs/tinmeg1_morphed/539_PO60_90-lh.stc-lh.stc'\n",
    "brain_labels = mne.read_labels_from_annot(subject='fsaverage', parc='aparc')[:-1] # 68 labels\n",
    "fs_dir = fetch_fsaverage(verbose=False)\n",
    "src_fname = op.join(fs_dir, \"bem\", \"fsaverage-ico-5-src.fif\")\n",
    "src = mne.read_source_spaces(src_fname, verbose=False)\n",
    "bl_idx = -1\n",
    "# extracting time course from source_estimate object in label index 0 (bankssts-lh)\n",
    "stc = mne.read_source_estimate(fname=stc_fname, subject='fsaverage')\n",
    "stc_v_label = stc.in_label(brain_labels[bl_idx])\n",
    "modes = (\"mean\", \"mean_flip\", \"pca_flip\", \"max\")\n",
    "tcs = dict()\n",
    "for mode in modes:\n",
    "    tcs[mode] = stc.extract_label_time_course(brain_labels[bl_idx], src, mode=mode, verbose=False)\n",
    "\n",
    "# plotting\n",
    "fig, ax = plt.subplots(1,1, figsize=(11,5))\n",
    "t = 1e3 * stc.times\n",
    "ax.plot(t, stc_v_label.data.T, \"k\", linewidth=0.5, alpha=0.2)\n",
    "for mode, tc in tcs.items():\n",
    "    ax.plot(t, tc[0], linewidth=3, label=str(mode))\n",
    "\n",
    "ax.legend(loc=\"upper right\")\n",
    "ax.set(xlabel=\"Time (ms)\", ylabel=\"Source amplitude\",\n",
    "    title=\"Activations in Label %r\" % (brain_labels[bl_idx].name))\n",
    "mne.viz.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading all sibjects\n",
    "directory = '/Users/payamsadeghishabestari/KI_MEG/stcs/tinmeg1_morphed'\n",
    "stc_files_list = []\n",
    "event = 'GP60_i240'\n",
    "for filename in sorted(os.listdir(directory)): \n",
    "    f = os.path.join(directory, filename)\n",
    "    if os.path.isfile(f) and f.endswith(\"-lh.stc\") and event in f: # or -rh\n",
    "            stc_files_list.append(f)\n",
    "\n",
    "# initializing\n",
    "brain_labels = mne.read_labels_from_annot(subject='fsaverage', parc='aparc')[:-1] # 68 labels\n",
    "fs_dir = fetch_fsaverage(verbose=False)\n",
    "src_fname = op.join(fs_dir, \"bem\", \"fsaverage-ico-5-src.fif\")\n",
    "src = mne.read_source_spaces(src_fname, verbose=False)\n",
    "rh_labels = [bl.name for bl in brain_labels if '-rh' in bl.name]\n",
    "lh_labels = [bl.name for bl in brain_labels if '-lh' in bl.name]\n",
    "dict_max_rh_label = {} \n",
    "dict_max_lh_label = {} \n",
    "\n",
    "for stc_fname in tqdm(stc_files_list):\n",
    "    subject_id = stc_fname[58:61]\n",
    "    stc = mne.read_source_estimate(fname=stc_fname, subject='fsaverage')\n",
    "    \n",
    "    tcs_max_rh = []\n",
    "    tcs_max_lh = []\n",
    "    for bl_idx in range(len(brain_labels)):\n",
    "        if '-rh' in brain_labels[bl_idx].name:\n",
    "            tcs_max_rh.append(stc.extract_label_time_course(brain_labels[bl_idx], src, mode='mean', verbose=False).max())\n",
    "        if '-lh' in brain_labels[bl_idx].name:\n",
    "            tcs_max_lh.append(stc.extract_label_time_course(brain_labels[bl_idx], src, mode='mean', verbose=False).max())\n",
    "\n",
    "    bl_rh_max = rh_labels[np.argmax(np.array(tcs_max_rh))]\n",
    "    bl_lh_max = lh_labels[np.argmax(np.array(tcs_max_lh))]\n",
    "\n",
    "    dict_max_rh_label[subject_id] = bl_rh_max\n",
    "    dict_max_lh_label[subject_id] = bl_lh_max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making big dataframe with all information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making big dataframe for transverstemporal rh/lh\n",
    "my_dict = {'subject ID': [], 'Stimulus': [], 'Hemisphere': [], 'latency': [],\n",
    "        'PSNR': [], 'peak value (30ms)': [], 'peak value (100ms)': [], 'area value (30ms)': [],\n",
    "        'area value (100ms)': [], 'amplitude inhibition (30ms)': [], 'area inhibition (30ms)': [],\n",
    "        'amplitude inhibition (100ms)': [], 'area inhibition (100ms)': [], 'EOG peak': [],\n",
    "        'EOG ptp': [], 'EOG area (30ms)': [], 'EOG area (100ms)': [], 'EOG peak latency': []} \n",
    "\n",
    "# events = ['PO60_70', 'PO60_75', 'PO60_80', 'PO60_85', 'PO60_90', 'PO60_95',\n",
    "#         'PO70_75', 'PO70_80', 'PO70_85', 'PO70_90', 'PO70_95',\n",
    "#         'GP60_i0', 'GP60_i60', 'GP60_i120', 'GP60_i240',\n",
    "#         'GP70_i0', 'GP70_i60', 'GP70_i120', 'GP70_i240',\n",
    "#         'GO_60', 'GO_70']\n",
    "\n",
    "events = ['GPP_00', 'GPG_00', 'PO_00', 'GO_00', 'PPP_00', 'PPG_00',\n",
    "        'GPP_03', 'GPG_03', 'PO_03', 'GO_03',\n",
    "        'GPP_08', 'GPG_08', 'PO_08', 'GO_08',\n",
    "        'GPP_30', 'GPG_30', 'PO_30', 'GO_30',\n",
    "        'GPP_33', 'GPG_33', 'PO_33', 'GO_33',\n",
    "        'GPP_38', 'GPG_38', 'PO_38', 'GO_38',\n",
    "        'GPP_80', 'GPG_80', 'PO_80', 'GO_80',\n",
    "        'GPP_83', 'GPG_83', 'PO_83', 'GO_83',\n",
    "        'GPP_88', 'GPG_88', 'PO_88', 'GO_88']\n",
    "\n",
    "# events = ['GPP_00', 'GPG_00', 'PO_00', 'GO_00', 'PPP_00', 'PPG_00',\n",
    "#         'GPP_03', 'GPG_03', 'PO_03', 'GO_03',\n",
    "#         'GPP_08', 'GPG_08', 'PO_08', 'GO_08']\n",
    "\n",
    "# subjects = ['539', '697', '750', '756', '832', '835', '836', '838', '839',\n",
    "#             '840', '841', '842', '844', '845', '847', '849', '850', '852', '853',\n",
    "#             '856', '857', '858', '859', '861', '862', '863'] # should I exclude 3 subjects?\n",
    "\n",
    "subjects = ['916', '979', '980', '981', '982', '983', '984', '986', '988']\n",
    "\n",
    "# subjects = ['1004', '1006', '1008', '1009', '1017', '1021', '1025', '1031',\n",
    "#             '1032', '1033', '1034', '1035', '1037', '1038', '1044', '1045', '1047', '1048']\n",
    "\n",
    "brain_labels = mne.read_labels_from_annot(subject='fsaverage', parc='aparc')[:-1] # 68 labels\n",
    "fs_dir = fetch_fsaverage(verbose=False)\n",
    "src_fname = op.join(fs_dir, \"bem\", \"fsaverage-ico-5-src.fif\")\n",
    "src = mne.read_source_spaces(src_fname, verbose=False)\n",
    "directory_stcs = '/Users/payamsadeghishabestari/KI_MEG/stcs/tinmeg2_morphed'\n",
    "directory_eps = '/Users/payamsadeghishabestari/KI_MEG/epochs/tinmeg2/epochs_bads_dropped'\n",
    "\n",
    "# looping over all files\n",
    "for subject in tqdm(subjects):\n",
    "    for stim in events:\n",
    "        for hemi in ['lh', 'rh']:\n",
    "            for filename in sorted(os.listdir(directory_stcs)): \n",
    "                f = os.path.join(directory_stcs, filename)\n",
    "                if os.path.isfile(f) and f.endswith(f\"-{hemi}.stc\") and stim in f and subject in f:\n",
    "                    \n",
    "                    # reading source estimate file\n",
    "                    stc_fname = f\n",
    "                    stc = mne.read_source_estimate(fname=stc_fname, subject='fsaverage')\n",
    "                    \n",
    "                    # reading epoch file for eog response\n",
    "                    for filename in sorted(os.listdir(directory_eps)): \n",
    "                        f = os.path.join(directory_eps, filename)\n",
    "                        if os.path.isfile(f) and f.endswith('-epo.fif') and subject in f:\n",
    "                            ep_fname = f\n",
    "                            ep = mne.read_epochs(fname=ep_fname, preload=True, verbose=False)\n",
    "                    \n",
    "                    eog_peak_value = abs(np.squeeze(ep[stim].get_data(picks=['EOG002'])).mean(axis=0)[75:].min() * 1e6) # only positive\n",
    "                    argmin = np.squeeze(ep[stim].get_data(picks=['EOG002'])).mean(axis=0)[75:].argmin() + 75\n",
    "                    eog_peak_time = np.linspace(-300, 300, 151)[argmin]\n",
    "                    (t1, t2) = (argmin - 5, argmin + 4)\n",
    "                    (t3, t4) = (argmin - 14, argmin + 13)\n",
    "                    my_dict['EOG peak'].append(eog_peak_value)\n",
    "                    my_dict['EOG ptp'].append(np.ptp(np.squeeze(ep[stim].get_data(picks=['EOG002'])).mean(axis=0)[75:]) * 1e6)\n",
    "                    my_dict['EOG area (30ms)'].append(abs(np.squeeze(ep[stim].get_data(picks=['EOG002'])).mean(axis=0)[t1:t2].sum() * 1e6))\n",
    "                    my_dict['EOG area (100ms)'].append(abs(np.squeeze(ep[stim].get_data(picks=['EOG002'])).mean(axis=0)[t3:t4].sum() * 1e6))\n",
    "                    my_dict['EOG peak latency'].append(eog_peak_time)\n",
    "                    \n",
    "                    # localizing the brain label\n",
    "                    if hemi == 'rh':\n",
    "                        bl_idx = -1 # transversetemporal-rh\n",
    "                    if hemi == 'lh':\n",
    "                        bl_idx = -2 # transversetemporal-lh\n",
    "\n",
    "                    # computing some params in stc object   \n",
    "                    tcs_noise_avg = stc.extract_label_time_course(brain_labels[bl_idx], src, mode='mean', verbose=False)[:,:76].mean()\n",
    "                    tcs_peak_100ms = stc.extract_label_time_course(brain_labels[bl_idx], src, mode='mean', verbose=False)[:,87:114].max()\n",
    "                    tcs_peak_30ms = stc.extract_label_time_course(brain_labels[bl_idx], src, mode='mean', verbose=False)[:,96:105].max()\n",
    "                    tcs_area_100ms = stc.extract_label_time_course(brain_labels[bl_idx], src, mode='mean', verbose=False)[:,87:114].sum()\n",
    "                    tcs_area_30ms = stc.extract_label_time_course(brain_labels[bl_idx], src, mode='mean', verbose=False)[:,96:105].sum()\n",
    "                    \n",
    "                    # computing inhibition indexes for tinmeg1\n",
    "                    # if '60' in stim and '70' not in stim:\n",
    "                    #     stc_fname_stn = f'/Users/payamsadeghishabestari/KI_MEG/stcs/tinmeg1_morphed/{subject}_PO60_90-lh.stc-lh.stc'\n",
    "                    #     stc_stn = mne.read_source_estimate(fname=stc_fname_stn, subject='fsaverage')\n",
    "                    #     tcs_peak_30ms_stn = stc_stn.extract_label_time_course(brain_labels[bl_idx],\n",
    "                    #                                                             src, mode='mean', verbose=False)[:,96:105].max()\n",
    "                    #     tcs_area_30ms_stn = stc_stn.extract_label_time_course(brain_labels[bl_idx], src, mode='mean', verbose=False)[:,96:105].sum()\n",
    "                    #     tcs_peak_100ms_stn = stc_stn.extract_label_time_course(brain_labels[bl_idx],\n",
    "                    #                                                             src, mode='mean', verbose=False)[:,87:114].max()\n",
    "                    #     tcs_area_100ms_stn = stc_stn.extract_label_time_course(brain_labels[bl_idx], src, mode='mean', verbose=False)[:,87:114].sum()\n",
    "\n",
    "                    # if '70' in stim:\n",
    "                    #     stc_fname_stn = f'/Users/payamsadeghishabestari/KI_MEG/stcs/tinmeg1_morphed/{subject}_PO70_90-lh.stc-lh.stc'\n",
    "                    #     stc_stn = mne.read_source_estimate(fname=stc_fname_stn, subject='fsaverage')\n",
    "                    #     tcs_peak_30ms_stn = stc_stn.extract_label_time_course(brain_labels[bl_idx],\n",
    "                    #                                                             src, mode='mean', verbose=False)[:,96:105].max()\n",
    "                    #     tcs_area_30ms_stn = stc_stn.extract_label_time_course(brain_labels[bl_idx], src, mode='mean', verbose=False)[:,96:105].sum()\n",
    "                    #     tcs_peak_100ms_stn = stc_stn.extract_label_time_course(brain_labels[bl_idx],\n",
    "                    #                                                             src, mode='mean', verbose=False)[:,87:114].max()\n",
    "                    #     tcs_area_100ms_stn = stc_stn.extract_label_time_course(brain_labels[bl_idx], src, mode='mean', verbose=False)[:,87:114].sum()\n",
    "            \n",
    "                    # computing inhibition indexes for tinmeg2\n",
    "                    stc_fname_stn = f'/Users/payamsadeghishabestari/KI_MEG/stcs/tinmeg2_morphed/{subject}_PO_{stim[-2:]}-lh.stc-lh.stc'\n",
    "                    stc_stn = mne.read_source_estimate(fname=stc_fname_stn, subject='fsaverage')\n",
    "                    tcs_peak_30ms_stn = stc_stn.extract_label_time_course(brain_labels[bl_idx],\n",
    "                                                                            src, mode='mean', verbose=False)[:,96:105].max()\n",
    "                    tcs_area_30ms_stn = stc_stn.extract_label_time_course(brain_labels[bl_idx], src, mode='mean', verbose=False)[:,96:105].sum()\n",
    "                    tcs_peak_100ms_stn = stc_stn.extract_label_time_course(brain_labels[bl_idx],\n",
    "                                                                            src, mode='mean', verbose=False)[:,87:114].max()\n",
    "                    tcs_area_100ms_stn = stc_stn.extract_label_time_course(brain_labels[bl_idx], src, mode='mean', verbose=False)[:,87:114].sum()\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    my_dict['amplitude inhibition (30ms)'].append((1 - (tcs_peak_30ms / tcs_peak_30ms_stn)) * 100)\n",
    "                    my_dict['area inhibition (30ms)'].append((1 - (tcs_area_30ms / tcs_area_30ms_stn)) * 100)\n",
    "                    my_dict['amplitude inhibition (100ms)'].append((1 - (tcs_peak_100ms / tcs_peak_100ms_stn)) * 100)\n",
    "                    my_dict['area inhibition (100ms)'].append((1 - (tcs_area_100ms / tcs_area_100ms_stn)) * 100)\n",
    "\n",
    "                    # putting in the dictionary\n",
    "                    my_dict['subject ID'].append(subject)\n",
    "                    my_dict['Stimulus'].append(stim)\n",
    "                    my_dict['Hemisphere'].append(hemi)\n",
    "                    my_dict['latency'].append(stc.extract_label_time_course(brain_labels[bl_idx], src,\n",
    "                                                                            mode='mean', verbose=False)[:,87:114].argmax() + 87) \n",
    "                    my_dict['PSNR'].append(20 * np.log10(tcs_peak_30ms / tcs_noise_avg))\n",
    "                    my_dict['peak value (30ms)'].append(tcs_peak_30ms)\n",
    "                    my_dict['peak value (100ms)'].append(tcs_peak_100ms)\n",
    "                    my_dict['area value (30ms)'].append(tcs_area_30ms)\n",
    "                    my_dict['area value (100ms)'].append(tcs_area_100ms)\n",
    "                    \n",
    "df = pd.DataFrame(my_dict)\n",
    "# save it\n",
    "df.to_csv('/Users/payamsadeghishabestari/KI_MEG/dataframes/tinmeg2_transverstemporal.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making big dataframe total left and right hemispheres\n",
    "my_dict = {'subject ID': [], 'Stimulus': [], 'Hemisphere': [], 'latency': [],\n",
    "        'PSNR': [], 'peak value (30ms)': [], 'peak value (100ms)': [], 'area value (30ms)': [],\n",
    "        'area value (100ms)': [], 'amplitude inhibition (30ms)': [], 'area inhibition (30ms)': [],\n",
    "        'amplitude inhibition (100ms)': [], 'area inhibition (100ms)': [], 'EOG peak': [],\n",
    "        'EOG ptp': [], 'EOG area (30ms)': [], 'EOG area (100ms)': []}\n",
    "\n",
    "events = ['PO60_70', 'PO60_75', 'PO60_80', 'PO60_85', 'PO60_90', 'PO60_95',\n",
    "        'PO70_75', 'PO70_80', 'PO70_85', 'PO70_90', 'PO70_95',\n",
    "        'GP60_i0', 'GP60_i60', 'GP60_i120', 'GP60_i240',\n",
    "        'GP70_i0', 'GP70_i60', 'GP70_i120', 'GP70_i240',\n",
    "        'GO_60', 'GO_70']\n",
    "\n",
    "subjects = ['539', '697', '750', '756', '832', '835', '836', '838', '839',\n",
    "            '840', '841', '842', '844', '845', '847', '849', '850', '852', '853',\n",
    "            '856', '857', '858', '859', '861', '862', '863'] \n",
    "\n",
    "brain_labels = mne.read_labels_from_annot(subject='fsaverage', parc='aparc')[:-1] # 68 labels\n",
    "fs_dir = fetch_fsaverage(verbose=False)\n",
    "src_fname = op.join(fs_dir, \"bem\", \"fsaverage-ico-5-src.fif\")\n",
    "src = mne.read_source_spaces(src_fname, verbose=False)\n",
    "directory_stcs = '/Users/payamsadeghishabestari/KI_MEG/stcs/tinmeg1_morphed'\n",
    "directory_eps = '/Users/payamsadeghishabestari/KI_MEG/epochs/tinmeg1'\n",
    "\n",
    "# looping over all files\n",
    "for subject in tqdm(subjects):\n",
    "    for stim in events:\n",
    "        for hemi in ['lh', 'rh']:\n",
    "            for filename in sorted(os.listdir(directory_stcs)): \n",
    "                f = os.path.join(directory_stcs, filename)\n",
    "                if os.path.isfile(f) and f.endswith(f\"-{hemi}.stc\") and stim in f and subject in f:\n",
    "                    \n",
    "                    # reading source estimate file\n",
    "                    stc_fname = f\n",
    "                    stc = mne.read_source_estimate(fname=stc_fname, subject='fsaverage')\n",
    "                    \n",
    "                    # reading epoch file for eog response\n",
    "                    for filename in sorted(os.listdir(directory_eps)): \n",
    "                        f = os.path.join(directory_eps, filename)\n",
    "                        if os.path.isfile(f) and f.endswith('-epo.fif') and subject in f:\n",
    "                            ep_fname = f\n",
    "                            ep = mne.read_epochs(fname=ep_fname, preload=True, verbose=False)\n",
    "                    \n",
    "                    my_dict['EOG peak'].append(abs(np.squeeze(ep[stim].get_data(picks=['EOG002'])).mean(axis=0).min() * 1e6))\n",
    "                    my_dict['EOG ptp'].append(np.ptp(np.squeeze(ep[stim].get_data(picks=['EOG002'])).mean(axis=0)) * 1e6)\n",
    "                    my_dict['EOG area (30ms)'].append(abs(np.squeeze(ep[stim].get_data(picks=['EOG002'])).mean(axis=0)[96:105].sum() * 1e6))\n",
    "                    my_dict['EOG area (100ms)'].append(abs(np.squeeze(ep[stim].get_data(picks=['EOG002'])).mean(axis=0)[87:114].sum() * 1e6))\n",
    "                    \n",
    "                    # localizing the brain label\n",
    "                    if hemi == 'rh':\n",
    "                        tcs_noise_avg = stc.rh_data.mean(axis=0)[:76].mean()\n",
    "                        tcs_peak_100ms = stc.rh_data.mean(axis=0)[87:114].max()\n",
    "                        tcs_peak_30ms = stc.rh_data.mean(axis=0)[96:105].max()\n",
    "                        tcs_area_100ms = stc.rh_data.mean(axis=0)[87:114].sum()\n",
    "                        tcs_area_30ms = stc.rh_data.mean(axis=0)[96:105].sum()\n",
    "                        check = 1\n",
    "\n",
    "                    if hemi == 'lh':\n",
    "                        tcs_noise_avg = stc.lh_data.mean(axis=0)[:76].mean()\n",
    "                        tcs_peak_100ms = stc.lh_data.mean(axis=0)[87:114].max()\n",
    "                        tcs_peak_30ms = stc.lh_data.mean(axis=0)[96:105].max()\n",
    "                        tcs_area_100ms = stc.lh_data.mean(axis=0)[87:114].sum()\n",
    "                        tcs_area_30ms = stc.lh_data.mean(axis=0)[96:105].sum()\n",
    "                        check = 2\n",
    "\n",
    "                    # computing inhibition indexes\n",
    "                    if '60' in stim and '70' not in stim and check==1:\n",
    "                        stc_fname_stn = f'/Users/payamsadeghishabestari/KI_MEG/stcs/tinmeg1_morphed/{subject}_PO60_90-lh.stc-lh.stc'\n",
    "                        stc_stn = mne.read_source_estimate(fname=stc_fname_stn, subject='fsaverage')\n",
    "                        tcs_peak_30ms_stn = stc_stn.rh_data.mean(axis=0)[96:105].max()\n",
    "                        tcs_area_30ms_stn = stc_stn.rh_data.mean(axis=0)[96:105].sum()\n",
    "                        tcs_peak_100ms_stn = stc_stn.rh_data.mean(axis=0)[87:114].max()\n",
    "                        tcs_area_100ms_stn = stc_stn.rh_data.mean(axis=0)[87:114].sum()\n",
    "\n",
    "                    if '60' in stim and '70' not in stim and check==2:\n",
    "                        stc_fname_stn = f'/Users/payamsadeghishabestari/KI_MEG/stcs/tinmeg1_morphed/{subject}_PO60_90-lh.stc-lh.stc'\n",
    "                        stc_stn = mne.read_source_estimate(fname=stc_fname_stn, subject='fsaverage')\n",
    "                        tcs_peak_30ms_stn = stc_stn.lh_data.mean(axis=0)[96:105].max()\n",
    "                        tcs_area_30ms_stn = stc_stn.lh_data.mean(axis=0)[96:105].sum()\n",
    "                        tcs_peak_100ms_stn = stc_stn.lh_data.mean(axis=0)[87:114].max()\n",
    "                        tcs_area_100ms_stn = stc_stn.lh_data.mean(axis=0)[87:114].sum()\n",
    "\n",
    "                    if '70' in stim and check==1:\n",
    "                        stc_fname_stn = f'/Users/payamsadeghishabestari/KI_MEG/stcs/tinmeg1_morphed/{subject}_PO70_90-lh.stc-lh.stc'\n",
    "                        stc_stn = mne.read_source_estimate(fname=stc_fname_stn, subject='fsaverage')\n",
    "                        tcs_peak_30ms_stn = stc_stn.rh_data.mean(axis=0)[96:105].max()\n",
    "                        tcs_area_30ms_stn = stc_stn.rh_data.mean(axis=0)[96:105].sum()\n",
    "                        tcs_peak_100ms_stn = stc_stn.rh_data.mean(axis=0)[87:114].max()\n",
    "                        tcs_area_100ms_stn = stc_stn.rh_data.mean(axis=0)[87:114].sum()\n",
    "\n",
    "                    if '70' in stim and check==2:\n",
    "                        stc_fname_stn = f'/Users/payamsadeghishabestari/KI_MEG/stcs/tinmeg1_morphed/{subject}_PO70_90-lh.stc-lh.stc'\n",
    "                        stc_stn = mne.read_source_estimate(fname=stc_fname_stn, subject='fsaverage')\n",
    "                        tcs_peak_30ms_stn = stc_stn.lh_data.mean(axis=0)[96:105].max()\n",
    "                        tcs_area_30ms_stn = stc_stn.lh_data.mean(axis=0)[96:105].sum()\n",
    "                        tcs_peak_100ms_stn = stc_stn.lh_data.mean(axis=0)[87:114].max()\n",
    "                        tcs_area_100ms_stn = stc_stn.lh_data.mean(axis=0)[87:114].sum()\n",
    "            \n",
    "                    \n",
    "                    my_dict['amplitude inhibition (30ms)'].append((1 - (tcs_peak_30ms / tcs_peak_30ms_stn)) * 100)\n",
    "                    my_dict['area inhibition (30ms)'].append((1 - (tcs_area_30ms / tcs_area_30ms_stn)) * 100)\n",
    "                    my_dict['amplitude inhibition (100ms)'].append((1 - (tcs_peak_100ms / tcs_peak_100ms_stn)) * 100)\n",
    "                    my_dict['area inhibition (100ms)'].append((1 - (tcs_area_100ms / tcs_area_100ms_stn)) * 100)\n",
    "\n",
    "                    if check==1:\n",
    "                        my_dict['latency'].append(stc.rh_data.mean(axis=0)[87:114].argmax() + 87)\n",
    "                    if check==2:\n",
    "                        my_dict['latency'].append(stc.lh_data.mean(axis=0)[87:114].argmax() + 87)     \n",
    "                    \n",
    "                    # putting in the dictionary\n",
    "                    my_dict['subject ID'].append(subject)\n",
    "                    my_dict['Stimulus'].append(stim)\n",
    "                    my_dict['Hemisphere'].append(hemi)\n",
    "                    my_dict['PSNR'].append(20 * np.log10(tcs_peak_30ms / tcs_noise_avg))\n",
    "                    my_dict['peak value (30ms)'].append(tcs_peak_30ms)\n",
    "                    my_dict['peak value (100ms)'].append(tcs_peak_100ms)\n",
    "                    my_dict['area value (30ms)'].append(tcs_area_30ms)\n",
    "                    my_dict['area value (100ms)'].append(tcs_area_100ms)\n",
    "                    \n",
    "df = pd.DataFrame(my_dict)\n",
    "# save it\n",
    "df.to_csv('/Users/payamsadeghishabestari/KI_MEG/dataframe_tinmeg1_hemisphere.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting tinmeg1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataframe and remove three subjects\n",
    "df = pd.read_csv('/Users/payamsadeghishabestari/KI_MEG/dataframes/tinmeg1_transverstemporal.csv') \n",
    "mask = df['subject ID'].isin(['697', '750', '853'])\n",
    "df = df[~mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding an extra column to the dataframe (eog inhibition)\n",
    "subject_ids = np.array(df['subject ID']).astype(str)\n",
    "stimuli = np.array(df['Stimulus']).astype(str)\n",
    "eog_peaks = np.array(df['EOG peak'])\n",
    "eog_ptps = np.array(df['EOG ptp'])\n",
    "eog_areas = np.array(df['EOG area (30ms)'])\n",
    "\n",
    "eog_amp_inhibits = []\n",
    "eog_ptp_inhibits = []\n",
    "eog_area_inhibits = []\n",
    "for idx, (eog_peak, eog_ptp, eog_area) in enumerate(zip(eog_peaks, eog_ptps, eog_areas)):\n",
    "    sub_id = subject_ids[idx]\n",
    "    stimulus = stimuli[idx]\n",
    "    array1 = np.where(subject_ids == sub_id)[0]\n",
    "    \n",
    "    if '60' in stimulus:\n",
    "        array2 = np.where(stimuli == 'PO60_90')[0]\n",
    "    if '70' in stimulus:\n",
    "        array2 = np.where(stimuli == 'PO70_90')[0]\n",
    "    \n",
    "    set1 = set(array1)\n",
    "    set2 = set(array2)\n",
    "    common_idx = list(set1.intersection(set2))[0]\n",
    "    eog_peak_stn = eog_peaks[common_idx]\n",
    "    eog_ptp_stn = eog_ptps[common_idx]\n",
    "    eog_area_stn = eog_areas[common_idx]\n",
    "    \n",
    "    eog_amp_inhibit = (1 - eog_peak / eog_peak_stn) * 100\n",
    "    eog_ptp_inhibit = (1 - eog_ptp / eog_ptp_stn) * 100\n",
    "    eog_area_inhibit = (1 - eog_area / eog_area_stn) * 100\n",
    "    \n",
    "    eog_amp_inhibits.append(eog_amp_inhibit)\n",
    "    eog_ptp_inhibits.append(eog_ptp_inhibit)\n",
    "    eog_area_inhibits.append(eog_area_inhibit)\n",
    "\n",
    "df['EOG peak inhibition'] = eog_amp_inhibits\n",
    "df['EOG ptp inhibition'] = eog_ptp_inhibits\n",
    "df['EOG area inhibition'] = eog_area_inhibits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting Figure 1 a\n",
    "fig, ax = plt.subplots(1, 1, figsize=(4,4))\n",
    "color='grey'\n",
    "order_1 = ['PO60_70', 'PO60_75', 'PO60_80', 'PO60_85', 'PO60_90', 'PO60_95']\n",
    "order_2 = ['PO60_70', 'PO70_75', 'PO70_80', 'PO70_85', 'PO70_90', 'PO70_95']\n",
    "df1 = df[df['Hemisphere']=='rh']\n",
    "sns.boxplot(data=df1, x='Stimulus', y='EOG peak', width=0.8, fill=False, gap=.1, linewidth=2,\n",
    "            saturation=0, color=color, order=order_1, ax=ax)\n",
    "color='#ff7f0e'\n",
    "sns.stripplot(data=df1, x='Stimulus', y='EOG peak',\n",
    "            dodge=False, size=3, color=color, order=order_1, ax=ax)\n",
    "ax.set_ylim([0, 150])\n",
    "ax.spines['top'].set_visible(False); ax.spines['right'].set_visible(False)\n",
    "\n",
    "# plotting Figure 1 b\n",
    "order_1 = ['PO60_70', 'PO60_75', 'PO60_80', 'PO60_85', 'PO60_90', 'PO60_95']\n",
    "order_2 = ['PO60_70', 'PO70_75', 'PO70_80', 'PO70_85', 'PO70_90', 'PO70_95']\n",
    "mask = df['Stimulus'].isin(order_1)\n",
    "df1 = df[mask]\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10,4))\n",
    "palette_color = ['#1f77b4', '#d62728'] \n",
    "sns.boxplot(data=df1, x='Stimulus', y='peak value (30ms)', hue='Hemisphere', width=0.8, fill=False, gap=.1, linewidth=2,\n",
    "            saturation=0.75, palette=palette_color, order=order_1, ax=ax)\n",
    "sns.stripplot(data=df1, x='Stimulus', y='peak value (30ms)', hue='Hemisphere',\n",
    "            dodge=True, size=3, palette=palette_color, order=order_1, ax=ax, legend=False)\n",
    "ax.spines['top'].set_visible(False); ax.spines['right'].set_visible(False)\n",
    "ax.legend(frameon=False, loc='upper left')\n",
    "\n",
    "# plotting Figure 1 c\n",
    "fig, ax = plt.subplots(figsize=(11, 4))\n",
    "colors = sns.color_palette('Set1')[1:5]\n",
    "# colors = np.array(sns.color_palette('Set1'))[[1, 2, 6, 7, 3, 0, 8],:]\n",
    "data = [19, 1, 2, 1]\n",
    "# data = [11, 4, 2, 2, 2, 1, 1]\n",
    "ingredients = ['transverstemporal-rh', 'bankssts-rh', 'entorhinal-rh', 'temporalpole-rh']\n",
    "# ingredients = ['transverstemporal-lh', 'bankssts-lh', 'rostralanteriorcingulate-lh', 'paracentral-lh',\n",
    "#                'entorhinal-lh', 'posteriorcingulate-lh', 'lateralorbitofrontal-lh']\n",
    "def func(pct, allvals):\n",
    "    absolute = int(np.round(pct/100.*np.sum(allvals)))\n",
    "    return f\"{pct:.1f}%\"\n",
    "wedges, autotexts = ax.pie(data, textprops=dict(color=\"w\"), colors=colors)\n",
    "legend_names = [f'{name} ({round(number/23*100, 1)}%)' for name, number in zip(ingredients, data)]\n",
    "ax.legend(wedges, legend_names, loc=\"center left\",\n",
    "            bbox_to_anchor=(1, 0, 0.5, 1), frameon=False, fontsize=12)\n",
    "\n",
    "# figure 1 d (needs to run previous parts)\n",
    "grand_ev_dict['PO60_90'].plot_topomap(times=0.1, time_unit='ms', contours=6)\n",
    "\n",
    "# figure 1 e\n",
    "directory = '/Users/payamsadeghishabestari/KI_MEG/stcs/tinmeg1_morphed'\n",
    "stc_files_list_rh = {'PO60_70': [], 'PO60_75': [], 'PO60_80': [],\n",
    "                'PO60_85': [], 'PO60_90': [], 'PO60_95': []}\n",
    "stc_files_list_lh = {'PO60_70': [], 'PO60_75': [], 'PO60_80': [],\n",
    "                'PO60_85': [], 'PO60_90': [], 'PO60_95': []}\n",
    "events = ['PO60_70', 'PO60_75', 'PO60_80', 'PO60_85', 'PO60_90', 'PO60_95']\n",
    "\n",
    "brain_labels = mne.read_labels_from_annot(subject='fsaverage', parc='aparc')[:-1] # 68 labels\n",
    "fs_dir = fetch_fsaverage(verbose=False)\n",
    "src_fname = op.join(fs_dir, \"bem\", \"fsaverage-ico-5-src.fif\")\n",
    "src = mne.read_source_spaces(src_fname, verbose=False)\n",
    "\n",
    "for event in events:\n",
    "    for filename in sorted(os.listdir(directory)): \n",
    "        f = os.path.join(directory, filename)\n",
    "        if os.path.isfile(f) and f.endswith(\"-lh.stc\") and event in f: # or -rh\n",
    "                stc = mne.read_source_estimate(fname=f, subject='fsaverage')\n",
    "                rh_data = stc.extract_label_time_course(brain_labels[-1], src, mode='mean', verbose=False)\n",
    "                lh_data = stc.extract_label_time_course(brain_labels[-2], src, mode='mean', verbose=False)\n",
    "                stc_files_list_rh[event].append(rh_data)\n",
    "                stc_files_list_lh[event].append(lh_data)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(7,3))\n",
    "lw = 0.5\n",
    "colors = ['#1f77b4', '#d62728']\n",
    "for event in events[:-1]:\n",
    "    data = np.squeeze(np.array(stc_files_list_lh[event])).mean(axis=0)\n",
    "    ax.plot(np.linspace(-300, 300, 151), data.T, label=event, linewidth=lw, color=colors[0])\n",
    "    lw += 0.4\n",
    "for event in events[-1:]:\n",
    "    data = np.squeeze(np.array(stc_files_list_lh[event])).mean(axis=0)\n",
    "    ax.plot(np.linspace(-300, 300, 151), data.T, label=event, linewidth=lw, color='k')\n",
    "    lw += 0.4\n",
    "\n",
    "ax.axvspan(50, 150, alpha=0.5, color='lightgrey')\n",
    "ax.vlines(0, 0.5, 6, colors='black',linestyles='--')\n",
    "for i in [-200, -100, 100, 200, 300]:\n",
    "    ax.vlines(i, 0.5, 6, colors='black',linestyles=':', linewidth=0.5)\n",
    "\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.legend(loc='upper right', ncols=6, fontsize=9, frameon=False, bbox_to_anchor=(0.6, 0.6, 0.6, 0.6))\n",
    "ax.set_xlim([-310, 310])\n",
    "ax.set_ylim([0, 6])\n",
    "\n",
    "# extra plot\n",
    "Brain = mne.viz.get_brain_class()\n",
    "clr = 0.85\n",
    "brain_kwargs = dict(alpha=1, background=\"white\", cortex=[(clr, clr, clr), (clr, clr, clr)], size=(800, 600), views='lateral')\n",
    "brain_labels = mne.read_labels_from_annot(subject='fsaverage', parc='aparc')[:-1] # 69 labels\n",
    "brain = Brain(\"fsaverage\", hemi=\"lh\", surf=\"pial_semi_inflated\", **brain_kwargs)\n",
    "brain.add_label(brain_labels[-2], hemi=\"lh\", color=\"#d62728\", borders=False, alpha=0.9)\n",
    "brain.show_view(roll=20, azimuth=30, elevation=80, distance=400)\n",
    "\n",
    "#### figure 1 f\n",
    "fig, axs = plt.subplots(1, 1, figsize=(6, 3))\n",
    "time_array = np.linspace(-300, 300, 151)\n",
    "stims = ['PO60_70', 'PO60_75', 'PO60_80', 'PO60_85', 'PO60_90', 'PO60_95']\n",
    "color = '#ff7f0e'\n",
    "lw = 0.5\n",
    "for stim in stims[:-1]:\n",
    "    axs.plot(time_array, abs(grand_ev_dict[stim].get_data(picks='EOG002')[0] * 1e6),\n",
    "            linewidth=lw, label=stim, color=color)\n",
    "    lw += 0.4\n",
    "for stim in stims[-1:]:\n",
    "    axs.plot(time_array, abs(grand_ev_dict[stim].get_data(picks='EOG002')[0] * 1e6),\n",
    "            linewidth=lw, label=stim, color='k')\n",
    "    \n",
    "axs.axvspan(50, 180, alpha=0.4, color='lightgrey')\n",
    "axs.legend(fontsize=9, frameon=False, bbox_to_anchor=(0.5, 0.1, 0.6, 0.6))\n",
    "axs.spines['top'].set_visible(False); axs.spines['right'].set_visible(False)\n",
    "for i in [-200, -100, 100, 200, 300]:\n",
    "    axs.vlines(i, -10, 60, colors='black',linestyles=':', linewidth=0.5)\n",
    "axs.vlines(0, -10, 60, colors='black',linestyles='--')\n",
    "axs.set_ylabel(f'EOG amplitude at 70 dB (µv)')\n",
    "axs.set_xlabel(f'Time (ms)')\n",
    "axs.set_ylim([-10, 60])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting Figure 2 a\n",
    "data1 = grand_ev_dict['GO_60'].get_data(picks='EOG002')[0] * 1e6\n",
    "data2 = grand_ev_dict['GO_70'].get_data(picks='EOG002')[0] * 1e6\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(6,3))\n",
    "ax.plot(np.linspace(-300, 300, 151), data1, label='GO_60', color='#ff7f0e', linewidth=2)\n",
    "ax.plot(np.linspace(-300, 300, 151), data2, label='GO_70', color='#9467bd', linewidth=2)\n",
    "ax.vlines(0, -10, 5, colors='black',linestyles='--')\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.legend(loc='upper left', fontsize=9, frameon=False)\n",
    "ax.set_xlim([-310, 310])\n",
    "for i in [-200, -100, 100, 200, 300]:\n",
    "    ax.vlines(i, -10, 5, colors='black',linestyles=':', linewidth=0.5)\n",
    "\n",
    "# plotting Figure 2 b\n",
    "directory = '/Users/payamsadeghishabestari/KI_MEG/stcs/tinmeg1_morphed'\n",
    "stc_files_list_rh = {'GO_60': [], 'GO_70': []}\n",
    "stc_files_list_lh = {'GO_60': [], 'GO_70': []}\n",
    "events = ['GO_60', 'GO_70']\n",
    "\n",
    "brain_labels = mne.read_labels_from_annot(subject='fsaverage', parc='aparc')[:-1] # 68 labels\n",
    "fs_dir = fetch_fsaverage(verbose=False)\n",
    "src_fname = op.join(fs_dir, \"bem\", \"fsaverage-ico-5-src.fif\")\n",
    "src = mne.read_source_spaces(src_fname, verbose=False)\n",
    "\n",
    "for event in events:\n",
    "    for filename in sorted(os.listdir(directory)): \n",
    "        f = os.path.join(directory, filename)\n",
    "        if os.path.isfile(f) and f.endswith(\"-lh.stc\") and event in f and '697' not in f and '750' not in f and '853' not in f:\n",
    "                stc = mne.read_source_estimate(fname=f, subject='fsaverage')\n",
    "                rh_data = stc.extract_label_time_course(brain_labels[-1], src, mode='mean', verbose=False)\n",
    "                lh_data = stc.extract_label_time_course(brain_labels[-2], src, mode='mean', verbose=False)\n",
    "                stc_files_list_rh[event].append(rh_data)\n",
    "                stc_files_list_lh[event].append(lh_data)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(6,3))\n",
    "colors = ['#d62728', '#1f77b4'] \n",
    "for event, clr in zip(events, colors):\n",
    "    data = np.squeeze(np.array(stc_files_list_rh[event])).mean(axis=0)\n",
    "    data_std = np.squeeze(np.array(stc_files_list_rh[event])).std(axis=0)\n",
    "    ax.plot(np.linspace(-300, 300, 151), data.T, label=event, color=clr)\n",
    "    ax.fill_between(np.linspace(-300, 300, 151), data.T - data_std.T,\n",
    "                    data.T + data_std.T, color=clr, alpha=0.1, edgecolor=\"none\")\n",
    "ax.vlines(0, 0.5, 8, colors='black',linestyles='--')\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.legend(loc='upper left', fontsize=9, frameon=False)\n",
    "ax.set_xlim([-310, 310])\n",
    "for i in [-200, -100, 100, 200, 300]:\n",
    "    ax.vlines(i, 0.5, 8, colors='black',linestyles=':', linewidth=0.5)\n",
    "\n",
    "# plotting Figure 2 c\n",
    "fig, ax = plt.subplots(1, 1, figsize=(4,4))\n",
    "palette_color = 'Set1'\n",
    "order_1 = ['GO_60', 'GO_70']\n",
    "order_2 = ['GO_70']\n",
    "df1 = df[df['Hemisphere']=='rh']\n",
    "sns.boxplot(data=df1, x='Stimulus', y='peak value (30ms)', width=0.4, fill=False, linewidth=2,\n",
    "            saturation=0.6, palette=palette_color, order=order_1, ax=ax)\n",
    "sns.stripplot(data=df1, x='Stimulus', y='peak value (30ms)',\n",
    "            dodge=False, size=4, palette=palette_color, order=order_1, ax=ax)\n",
    "ax.set_ylim([0, 13])\n",
    "ax.spines['top'].set_visible(False); ax.spines['right'].set_visible(False)\n",
    "\n",
    "# plotting Figure 2 e\n",
    "grand_ev_dict['GO_60'].plot_topomap(times=0.1, time_unit='ms', contours=6, vlim=(-240, 240))\n",
    "\n",
    "# plotting Figure 2 d\n",
    "brain_labels = mne.read_labels_from_annot(subject='fsaverage', parc='aparc')[:-1] # 68 labels\n",
    "fig, ax = plt.subplots(1,1, figsize=(10, 4))\n",
    "colors = np.array(sns.color_palette('Set1'))[[1, 2, 3, 4, 6, 0, 8],:]\n",
    "\n",
    "# data = [17, 1, 1, 1, 2, 1]\n",
    "data = [13, 2, 3, 1, 2, 1, 1]\n",
    "\n",
    "# ingredients = ['transverstemporal-rh', 'bankssts-rh', 'entorhinal-rh', 'temporalpole-rh']\n",
    "ingredients = [brain_labels[67].name, brain_labels[1].name,\n",
    "                brain_labels[9].name, brain_labels[0].name, brain_labels[66].name,\n",
    "                brain_labels[32].name, brain_labels[42].name]\n",
    "def func(pct, allvals):\n",
    "    absolute = int(np.round(pct/100.*np.sum(allvals)))\n",
    "    return f\"{pct:.1f}%\"\n",
    "wedges, autotexts = ax.pie(data, textprops=dict(color=\"w\"), colors=colors)\n",
    "legend_names = [f'{name} ({round(number/23*100, 1)}%)' for name, number in zip(ingredients, data)]\n",
    "ax.legend(wedges, legend_names, loc=\"center left\",\n",
    "        bbox_to_anchor=(1, 0, 0.5, 1), frameon=False, fontsize=12)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting Figure 3 a\n",
    "order_1 = ['GP60_i0', 'GP60_i60', 'GP60_i120', 'GP60_i240']\n",
    "order_2 = ['GP70_i0', 'GP70_i60', 'GP70_i120', 'GP70_i240']\n",
    "mask = df['Stimulus'].isin(order_1)\n",
    "df1 = df[mask]\n",
    "df2 = df1[df1['Hemisphere']=='rh']\n",
    "fig, ax = plt.subplots(1, 1, figsize=(5,3))\n",
    "palette_color = ['grey']\n",
    "sns.boxplot(data=df2, x='Stimulus', y='EOG area inhibition', width=0.5, fill=False, linewidth=2,\n",
    "            saturation=0.75, palette=palette_color, order=order_1, ax=ax)\n",
    "sns.stripplot(data=df2, x='Stimulus', y='EOG area inhibition',\n",
    "            dodge=False, size=3, palette=palette_color, order=order_1, ax=ax, legend=False)\n",
    "ax.spines['top'].set_visible(False); ax.spines['right'].set_visible(False)\n",
    "ax.legend(frameon=False, loc='upper right', bbox_to_anchor=(1.1, 1))\n",
    "ax.set_ylim([-50, 100])\n",
    "ax.hlines(0, -0.6, 3.6, colors='black',linestyles='--')\n",
    "ax.hlines(50, -0.6, 3.6, colors='grey',linestyles=':')\n",
    "ax.set_yticks([-50, 0, 50, 100])\n",
    "\n",
    "# plotting Figure 3 b\n",
    "order_1 = ['GP60_i0', 'GP60_i60', 'GP60_i120', 'GP60_i240']\n",
    "order_2 = ['GP70_i0', 'GP70_i60', 'GP70_i120', 'GP70_i240']\n",
    "mask = df['Stimulus'].isin(order_2)\n",
    "df1 = df[mask]\n",
    "fig, ax = plt.subplots(1, 1, figsize=(9,3))\n",
    "palette_color = ['#1f77b4', '#d62728']\n",
    "sns.boxplot(data=df1, x='Stimulus', y='area inhibition (30ms)', hue='Hemisphere', width=0.8, fill=False, gap=.1, linewidth=2,\n",
    "            saturation=0.75, palette=palette_color, order=order_2, ax=ax)\n",
    "sns.stripplot(data=df1, x='Stimulus', y='area inhibition (30ms)', hue='Hemisphere',\n",
    "            dodge=True, size=3, palette=palette_color, order=order_2, ax=ax, legend=False)\n",
    "ax.spines['top'].set_visible(False); ax.spines['right'].set_visible(False)\n",
    "ax.legend(frameon=False, loc='upper right', bbox_to_anchor=(1.1, 1))\n",
    "ax.set_ylim([-50, 100])\n",
    "ax.hlines(0, -0.6, 3.6, colors='black',linestyles='--')\n",
    "ax.hlines(50, -0.6, 3.6, colors='grey',linestyles=':')\n",
    "ax.set_yticks([-50, 0, 50, 100])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataframe and remove three subjects\n",
    "df = pd.read_csv('/Users/payamsadeghishabestari/KI_MEG/dataframes/tinmeg2_transverstemporal.csv') \n",
    "\n",
    "# plotting Figure 4 a \n",
    "order_1 = ['PO_00', 'PO_03', 'PO_08', 'PO_30', 'PO_33', 'PO_38', 'PO_80', 'PO_83', 'PO_88']\n",
    "\n",
    "mask = df['Stimulus'].isin(order_1)\n",
    "df1 = df[mask]\n",
    "fig, ax = plt.subplots(1, 1, figsize=(7,3))\n",
    "palette_color = ['#d62728', '#d62728', '#d62728',\n",
    "                '#1f77b4', '#1f77b4', '#1f77b4',\n",
    "                '#2ca02c', '#2ca02c', '#2ca02c']\n",
    "sns.boxplot(data=df1, x='Stimulus', y='EOG peak', width=0.3, fill=False, linewidth=2,\n",
    "            saturation=0.55, palette=palette_color, order=order_1, ax=ax)\n",
    "sns.stripplot(data=df1, x='Stimulus', y='EOG peak',\n",
    "            dodge=False, size=3, palette=palette_color, order=order_1, ax=ax, legend=False)\n",
    "ax.spines['top'].set_visible(False); ax.spines['right'].set_visible(False)\n",
    "ax.legend(frameon=False, loc='upper right', bbox_to_anchor=(1.1, 1))\n",
    "\n",
    "# plotting Figure 4 b \n",
    "order_1 = ['PO_00', 'PO_03', 'PO_08', 'PO_30', 'PO_33', 'PO_38', 'PO_80', 'PO_83', 'PO_88']\n",
    "mask = df['Stimulus'].isin(order_1)\n",
    "df1 = df[mask]\n",
    "fig, ax = plt.subplots(1, 1, figsize=(11,3))\n",
    "palette_color = ['#d62728', '#1f77b4']\n",
    "sns.boxplot(data=df1, x='Stimulus', y='peak value (30ms)', hue='Hemisphere',\n",
    "            width=0.5, fill=False, linewidth=2, saturation=0, palette=palette_color, gap=.1,\n",
    "            order=order_1, ax=ax)\n",
    "sns.stripplot(data=df1, x='Stimulus', y='peak value (30ms)', hue='Hemisphere',\n",
    "            dodge=True, size=3, palette=palette_color, order=order_1, ax=ax, legend=False)\n",
    "ax.spines['top'].set_visible(False); ax.spines['right'].set_visible(False)\n",
    "ax.legend(frameon=False, loc='upper right', bbox_to_anchor=(1.1, 1))\n",
    "\n",
    "# plotting Figure 4 c\n",
    "order_2 = ['GO_00', 'GO_03', 'GO_08', 'GO_30', 'GO_33', 'GO_38', 'GO_80', 'GO_83', 'GO_88']\n",
    "mask = df['Stimulus'].isin(order_2)\n",
    "df1 = df[mask]\n",
    "fig, ax = plt.subplots(1, 1, figsize=(11,3))\n",
    "palette_color = ['#d62728', '#1f77b4']\n",
    "sns.boxplot(data=df1, x='Stimulus', y='peak value (30ms)', hue='Hemisphere',\n",
    "            width=0.5, fill=False, linewidth=2, saturation=0, palette=palette_color, gap=.1,\n",
    "            order=order_2, ax=ax)\n",
    "sns.stripplot(data=df1, x='Stimulus', y='peak value (30ms)', hue='Hemisphere',\n",
    "            dodge=True, size=3, palette=palette_color, order=order_2, ax=ax, legend=False)\n",
    "ax.spines['top'].set_visible(False); ax.spines['right'].set_visible(False)\n",
    "ax.legend(frameon=False, loc='upper right', bbox_to_anchor=(1.1, 1))\n",
    "ax.set_ylim([0, 8.8])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# table 1\n",
    "evs1 = ['PO60_70', 'PO60_75', 'PO60_80', 'PO60_85', 'PO60_90', 'PO60_95']\n",
    "evs2 = ['PO70_75', 'PO70_80', 'PO70_85', 'PO70_90', 'PO70_95']\n",
    "for ev in evs2:\n",
    "    df1 = df[df['Stimulus']==ev]\n",
    "    df2 = df1[df1['Hemisphere']=='lh']\n",
    "    mean = df2['EOG peak latency'].mean()\n",
    "    std = df2['EOG peak latency'].std()\n",
    "    print(f'{round(mean, 2)} + {round(std, 2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# table 2\n",
    "df1 = df[df['Stimulus']=='GO_60']\n",
    "df2 = df1[df1['Hemisphere']=='rh']\n",
    "median = round(df2['latency'].median(), 2)\n",
    "std = round(df2[\"latency\"].std(), 2)\n",
    "print(f'{median} + {std}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# table 3\n",
    "evs1 = ['GP60_i0', 'GP60_i60', 'GP60_i120', 'GP60_i240']\n",
    "evs2 = ['GP70_i0', 'GP70_i60', 'GP70_i120', 'GP70_i240']\n",
    "for ev in evs2:\n",
    "    df1 = df[df['Stimulus']==ev]\n",
    "    df2 = df1[df1['Hemisphere']=='lh']\n",
    "    mean = df2['amplitude inhibition (30ms)'].median()\n",
    "    std = df2['amplitude inhibition (30ms)'].std()\n",
    "    print(f'{round(mean, 2)} + {round(std, 2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tinmeg3 plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events = ['GPP_00', 'GPG_00', 'PO_00', 'GO_00', 'PPP_00', 'PPG_00',\n",
    "        'GPP_03', 'GPG_03', 'PO_03', 'GO_03',\n",
    "        'GPP_08', 'GPG_08', 'PO_08', 'GO_08']\n",
    "# load dataframe and remove three subjects\n",
    "df = pd.read_csv('/Users/payamsadeghishabestari/KI_MEG/dataframes/tinmeg3_transverstemporal.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting 1\n",
    "order_1 = ['GPP_00', 'GPP_03', 'GPP_08']\n",
    "order_2 = ['GPG_00', 'GPG_03', 'GPG_08']\n",
    "\n",
    "mask = df['Stimulus'].isin(order_2)\n",
    "df1 = df[mask]\n",
    "fig, ax = plt.subplots(1, 1, figsize=(6,4))\n",
    "palette_color = ['#d62728', '#1f77b4']\n",
    "sns.boxplot(data=df1, x='Stimulus', y='area inhibition (30ms)', hue='Hemisphere', width=0.8, fill=False, gap=.1, linewidth=2,\n",
    "            saturation=0.75, palette=palette_color, order=order_2, ax=ax)\n",
    "sns.stripplot(data=df1, x='Stimulus', y='area inhibition (30ms)', hue='Hemisphere',\n",
    "            dodge=True, size=3, palette=palette_color, order=order_2, ax=ax, legend=False)\n",
    "ax.spines['top'].set_visible(False); ax.spines['right'].set_visible(False)\n",
    "ax.legend(frameon=False, loc='upper right', bbox_to_anchor=(1.1, 1))\n",
    "ax.set_ylim([-100, 100])\n",
    "ax.hlines(0, -0.6, 2.6, colors='black',linestyles='--')\n",
    "ax.hlines(50, -0.6, 2.6, colors='grey',linestyles=':')\n",
    "\n",
    "# plotting 2\n",
    "directory = '/Users/payamsadeghishabestari/KI_MEG/stcs/tinmeg3_morphed'\n",
    "ev_name = 'GPP'\n",
    "stc_files_list_rh = {f'{ev_name}_00': [], f'{ev_name}_03': [], f'{ev_name}_08': []}\n",
    "stc_files_list_lh = {f'{ev_name}_00': [], f'{ev_name}_03': [], f'{ev_name}_08': []}\n",
    "events = [f'{ev_name}_00', f'{ev_name}_03', f'{ev_name}_08']\n",
    "\n",
    "brain_labels = mne.read_labels_from_annot(subject='fsaverage', parc='aparc')[:-1] # 68 labels\n",
    "fs_dir = fetch_fsaverage(verbose=False)\n",
    "src_fname = op.join(fs_dir, \"bem\", \"fsaverage-ico-5-src.fif\")\n",
    "src = mne.read_source_spaces(src_fname, verbose=False)\n",
    "\n",
    "for event in events:\n",
    "    for filename in sorted(os.listdir(directory)): \n",
    "        f = os.path.join(directory, filename)\n",
    "        if os.path.isfile(f) and f.endswith(\"-lh.stc\") and event in f: # or -rh\n",
    "                stc = mne.read_source_estimate(fname=f, subject='fsaverage')\n",
    "                rh_data = stc.extract_label_time_course(brain_labels[-1], src, mode='mean', verbose=False)\n",
    "                lh_data = stc.extract_label_time_course(brain_labels[-2], src, mode='mean', verbose=False)\n",
    "                stc_files_list_rh[event].append(rh_data)\n",
    "                stc_files_list_lh[event].append(lh_data)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(6,3))\n",
    "colors = ['#d62728', '#1f77b4', '#2ca02c'] \n",
    "for event, clr in zip(events, colors):\n",
    "    data = np.squeeze(np.array(stc_files_list_lh[event])).mean(axis=0)\n",
    "    ax.plot(np.linspace(-300, 300, 151), data.T, label=event, color=clr)\n",
    "ax.vlines(0, 0.5, 6, colors='black',linestyles='--')\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.legend(loc='upper right', fontsize=9, frameon=False)\n",
    "ax.set_xlim([-310, 310])\n",
    "for i in [-300, -200, -100, 100, 200, 300]:\n",
    "    ax.vlines(i, 0.5, 6, colors='black',linestyles=':', linewidth=0.5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
